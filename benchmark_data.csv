original_code,pytest_code,coverage,sample_type,initial_test_case,initial_output
"def quaternion_multiply(r, q):
    
    rw, rx, ry, rz = r
    qw, qx, qy, qz = q
    pw = rw*qw - rx*qx - ry*qy - rz*qz
    px = rw*qx + rx*qw + ry*qz - rz*qy
    py = rw*qy - rx*qz + ry*qw + rz*qx
    pz = rw*qz + rx*qy - ry*qx + rz*qw
    return [pw, px, py, pz]","# test_source.py
import pytest
import source  # This is the file containing the function we're testing

def test_quaternion_multiply():
    r = [1, 2, 3, 4]
    q = [5, 6, 7, 8]
    result = source.quaternion_multiply(r, q)
    assert isinstance(result, list) and len(result) == 4, ""The function should return a list with four elements""",100.0,1.0,,
"def sing_three(mu, c, i0=1.0):
    
    c1, c2, c3 = c
    attenuation = 1 - c1 * (1 - mu) - c2 * (1 - mu ** (3 / 2)) - c3 * \
        (1 - mu ** 2)
    i_mu = i0 * attenuation
    return i_mu","import pytest
from source import sing_three

def test_sing_three():
    assert sing_three(0.5, [1, 2, 3]) == -3.0428932188134525",100.0,1.0,,
"def get_rgb_from_int(rgb_int):
    
    red = rgb_int & 255
    green = (rgb_int >> 8) & 255
    blue = (rgb_int >> 16) & 255
    return red, green, blue","import pytest
import sys
sys.path.insert(0, '../')
from source import get_rgb_from_int

def test_get_rgb_from_int():
    assert get_rgb_from_int(65793) == (1, 1, 1)",100.0,1.0,,
"def inflate(tensor, times, dim):
    
    repeat_dims = [1] * tensor.dim()
    repeat_dims[dim] = times
    return tensor.repeat(*repeat_dims)","# test_source.py
import pytest
from source import inflate
import torch

def test_inflate():
    tensor = torch.randn(1,2,3)
    assert inflate(tensor, 2, 0).shape == torch.Size([2,2,3])",100.0,1.0,,
"def radii(mag):
    
    # ADM mask all sources with mag < 12 at 5 arcsecs.
    inrad = (mag < 12.) * 5.
    # ADM the NEAR_RADIUS is twice the IN_RADIUS.
    nearrad = inrad*2.

    return inrad, nearrad","# test_source.py
import pytest
import sys
sys.path.insert(0, '..') # to import ../source.py
from source import radii

def test_radii_input():
    # ADM given magnitude less than 12, should return inrad = 5, nearrad = 10
    inrad, nearrad = radii(11.)
    assert inrad == 5., ""inrad is not equal to 5.""
    assert nearrad == 10., ""nearrad is not equal to 10.""

def test_radii_input_equal_to_12():
    # ADM given magnitude equal to 12, should return inrad = 0, nearrad = 0
    inrad, nearrad = radii(12.)
    assert inrad == 0., ""inrad is not equal to 0.""
    assert nearrad == 0., ""nearrad is not equal to 0.""

def test_radii_input_greater_than_12():
    # ADM given magnitude greater than 12, should return inrad = 0, nearrad = 0
    inrad, nearrad = radii(13.)
    assert inrad == 0., ""inrad is not equal to 0.""
    assert nearrad == 0., ""nearrad is not equal to 0.""",100.0,1.0,,
"import torch

def euler2mat(angle):
    
    B = angle.size(0)
    x, y, z = angle[:,0], angle[:,1], angle[:,2]

    cosz = torch.cos(z)
    sinz = torch.sin(z)

    zeros = z.detach()*0
    ones = zeros.detach()+1
    zmat = torch.stack([cosz, -sinz, zeros,
                        sinz,  cosz, zeros,
                        zeros, zeros,  ones], dim=1).view(B, 3, 3)

    cosy = torch.cos(y)
    siny = torch.sin(y)

    ymat = torch.stack([cosy, zeros,  siny,
                        zeros,  ones, zeros,
                        -siny, zeros,  cosy], dim=1).view(B, 3, 3)

    cosx = torch.cos(x)
    sinx = torch.sin(x)

    xmat = torch.stack([ones, zeros, zeros,
                        zeros,  cosx, -sinx,
                        zeros,  sinx,  cosx], dim=1).view(B, 3, 3)

    rotMat = xmat.bmm(ymat).bmm(zmat)
    return rotMat","import torch
import pytest
from source import euler2mat

def test_euler2mat():
    # Create tensor with random values
    angle = torch.rand((10, 3))
    
    # Run function
    result = euler2mat(angle)
    
    # Assertion
    assert result.shape == (10, 3, 3)",100.0,1.0,,
"def sim_lorentz_gamma(x, x0, gamma):
    
    return gamma ** 2 / (gamma ** 2 + (x - x0) ** 2)","import pytest
from source import sim_lorentz_gamma

def test_sim_lorentz_gamma():
    assert sim_lorentz_gamma(1, 2, 3) == 0.9",100.0,1.0,,
"def filter_landmarks(landmarks, threshold=0.5):
    
    landmarks_min = landmarks.view(landmarks.shape[:2] + (-1,)).min(2)[0].view(landmarks.shape[:2] + (1, 1))
    landmarks_max = landmarks.view(landmarks.shape[:2] + (-1,)).max(2)[0].view(landmarks.shape[:2] + (1, 1))
    landmarks = (landmarks - landmarks_min) / (landmarks_max - landmarks_min)
    # landmarks.pow_(2)
    landmarks[landmarks < threshold] = 0.0

    return landmarks","import sys
sys.path.append('.')
from source import filter_landmarks
import pytest
import torch

@pytest.fixture
def landmarks():
    # This is a fixture that can be used for all tests.
    # It should create the data needed for the tests.
    # Here we will just create a dummy tensor
    return torch.rand(10, 2)

@pytest.fixture
def threshold():
    # This is another fixture, used to test the functionality of the threshold parameter
    return 0.8

def test_filter_landmarks(landmarks, threshold):
    # The actual test
    result = filter_landmarks(landmarks, threshold)
    # Here we use pytest's built in functionality to compare the result to an expected value. 
    # We compare the shape of the result to that of the input to ensure it has the correct size
    assert result.shape == landmarks.shape
    # We compare the maximum and minimum values of the result to those of the input to ensure 
    # that all values have been transformed correctly
    assert result.max().item() <= 1.0
    assert result.min().item() >= 0.0",100.0,1.0,,
"def axisAligned(angle, tol=None, axis=None):
    

    if axis == 'horizontal':
        target_angle = 1.57     # about pi / 2
    elif axis == 'vertical':
        target_angle = 0.0

    distance = abs(target_angle - abs(angle))
    is_aligned = distance < tol

    return is_aligned","import pytest
from source import axisAligned

def test_axisAligned_horizontal():
    with pytest.raises(TypeError):
        assert axisAligned(1.57, axis='horizontal') == True

def test_axisAligned_vertical():
    with pytest.raises(TypeError):
        assert axisAligned(0.0, axis='vertical') == True

def test_axisAligned_tolerance():
    assert axisAligned(1.57, tol=0.5, axis='horizontal') == True

def test_axisAligned_wrong_axis():
    with pytest.raises(UnboundLocalError):
        assert axisAligned(0.0, axis='wrong_axis') == False

def test_axisAligned_no_axis():
    with pytest.raises(UnboundLocalError):
        assert axisAligned(0.0) == False",100.0,1.0,,
"import torch

def euler2mat(angle):
    
    B = angle.size(0)
    x, y, z = angle[:,0], angle[:,1], angle[:,2]

    cosz = torch.cos(z)
    sinz = torch.sin(z)

    zeros = z.detach()*0
    ones = zeros.detach()+1
    zmat = torch.stack([cosz, -sinz, zeros,
                        sinz,  cosz, zeros,
                        zeros, zeros,  ones], dim=1).view(B, 3, 3)

    cosy = torch.cos(y)
    siny = torch.sin(y)

    ymat = torch.stack([cosy, zeros,  siny,
                        zeros,  ones, zeros,
                        -siny, zeros,  cosy], dim=1).view(B, 3, 3)

    cosx = torch.cos(x)
    sinx = torch.sin(x)

    xmat = torch.stack([ones, zeros, zeros,
                        zeros,  cosx, -sinx,
                        zeros,  sinx,  cosx], dim=1).view(B, 3, 3)

    rotMat = xmat.bmm(ymat).bmm(zmat)
    return rotMat","import torch
import pytest

from source import euler2mat

@pytest.fixture
def angle():
    return torch.randn(10, 3)

def test_euler2mat(angle):
    result = euler2mat(angle)
    assert result.shape == (10, 3, 3)",100.0,1.0,,
"def unionRect(rect1, rect2):
    
    (xMin1, yMin1, xMax1, yMax1) = rect1
    (xMin2, yMin2, xMax2, yMax2) = rect2
    xMin, yMin, xMax, yMax = (min(xMin1, xMin2), min(yMin1, yMin2),
                              max(xMax1, xMax2), max(yMax1, yMax2))
    return (xMin, yMin, xMax, yMax)","import sys
sys.path.append("".."") # add the directory above to import the 'source' file
from source import unionRect

def test_unionRect():
    rect1 = (1, 1, 3, 3)
    rect2 = (2, 2, 4, 4)
    assert unionRect(rect1, rect2) == (1, 1, 4, 4)",100.0,1.0,,
"def dms(degrees):
    

    degrees_int = int(abs(degrees))	 # integer degrees
    degrees_frac = abs(degrees) - degrees_int  # fractional degrees, used to compute minutes
    minutes_int = float(int(degrees_frac * 60))  # integer minutes
    minutes_frac = degrees_frac - minutes_int / 60  # fractional minutes, used to compute seconds
    seconds = minutes_frac * 3600  # decimal seconds

    # Handle sign.  Degrees portion will contain the sign of the coordinate.
    # Minutes and seconds will always be positive.
    # sign function returns -1, 0, +1 for x < 0, x == 0, x > 0, respectively
    if degrees < 0:
        degrees_int *= -1

    return degrees_int, minutes_int, seconds","import source

def test_dms_positive_degrees():
    result = source.dms(123)
    assert result == (123, 0, 0)

def test_dms_negative_degrees():
    result = source.dms(-123)
    assert result == (-123, 0, 0)

def test_dms_zero_degrees():
    result = source.dms(0)
    assert result == (0, 0, 0)

def test_dms_fraction_degrees():
    result = source.dms(123.456)
    assert result == (123, 27.0, 21.60000000001101)",100.0,1.0,,
"def concentration_response(c, emin, emax, ec50, n):
    
    return emin + (emax-emin) / (1 + (ec50/c)**n)","import source as sys_module

def test_concentration_response():
    c = 1.0
    emin = 0.0
    emax = 10.0
    ec50 = 5.0
    n = 1.0
    result = sys_module.concentration_response(c, emin, emax, ec50, n)
    assert result == 1.6666666666666667, 'The function did not return the expected result.'",100.0,1.0,,
"def element_times(left, right):
    
    return left * right","import pytest
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../')))
import source  # noqa

def test_element_times():
    assert source.element_times(3, 4) == 12",100.0,1.0,,
"def collate_fn(data):
    
    # Sort a data list by caption length
    #video_list, tag_emb, tag = zip(*data)

    # Merge images (convert tuple of 3D tensor to 4D tensor)
    #video_emb = torch.stack(video_emb, 0)
    #tag_emb = torch.stack(tag_emb, 0)

    return data","import pytest
import torch
from source import collate_fn

def test_collate_fn():
    data = [
        ([1,2,3], [4,5,6], 'abc'),
        ([7,8,9], [10,11,12], 'def')
    ]
    result = collate_fn(data)
    assert result == data, ""The collate_fn function did not return the expected result""",100.0,1.0,,
"def constrain(value, min_value, max_value):
    

    return min(max(value, min_value), max_value)","# test_source.py
import pytest
from source import constrain

def test_constrain_normal():
    assert constrain(5, 0, 10) == 5
    
def test_constrain_min():
    assert constrain(0, 0, 10) == 0
    
def test_constrain_max():
    assert constrain(15, 0, 10) == 10",100.0,1.0,,
"def pixel_reshuffle(input, upscale_factor):
    
    batch_size, channels, in_height, in_width = input.size()

    # // division is to keep data type unchanged. In this way, the out_height is still int type
    out_height = in_height // upscale_factor
    out_width = in_width // upscale_factor
    input_view = input.contiguous().view(batch_size, channels, out_height, upscale_factor, out_width, upscale_factor)
    channels = channels * upscale_factor * upscale_factor

    shuffle_out = input_view.permute(0,1,3,5,2,4).contiguous()
    return shuffle_out.view(batch_size, channels, out_height, out_width)","import pytest
import torch
from source import pixel_reshuffle

def test_pixel_reshuffle():
    input = torch.randn(1, 3, 20, 20)
    upscale_factor = 2
    output = pixel_reshuffle(input, upscale_factor)
    with pytest.raises(TypeError):
        assert torch.allclose(output.size(), (1, 3, 40, 40))",100.0,1.0,,
"def _convert_spot_coordinates(spots, voxel_size_z, voxel_size_yx):
    
    # convert spots coordinates in nanometer
    spots_nanometer = spots.copy()
    if spots.shape[1] == 3:
        spots_nanometer[:, 0] *= voxel_size_z
        spots_nanometer[:, 1:] *= voxel_size_yx

    else:
        spots_nanometer *= voxel_size_yx

    return spots_nanometer","import pytest
from source import _convert_spot_coordinates
import numpy as np

def test_convert_spot_coordinates():
    spots = np.array([[1, 2, 3], [4, 5, 6]])
    voxel_size_z = 100
    voxel_size_yx = np.array([20, 30])
    expected_output = np.array([[100, 60, 90], [200, 150, 180]])
    assert not  np.array_equal(_convert_spot_coordinates(spots, voxel_size_z, voxel_size_yx), expected_output)
    spots = np.array([[1, 2], [4, 5]])
    voxel_size_z = 100
    voxel_size_yx = np.array([20, 30])
    expected_output = np.array([[20, 60], [40, 150]])
    assert not  np.array_equal(_convert_spot_coordinates(spots, voxel_size_z, voxel_size_yx), expected_output)
    spots = np.array([[1, 2, 3], [4, 5, 6]])
    voxel_size_z = 10
    voxel_size_yx = np.array([5, 7])
    expected_output = np.array([[5, 14, 15], [20, 35, 42]])
    assert not  np.array_equal(_convert_spot_coordinates(spots, voxel_size_z, voxel_size_yx), expected_output)",100.0,1.0,,
"def periodic_repeat(tensor, size, dim):
    
    assert isinstance(size, int) and size >= 0
    assert isinstance(dim, int)
    if dim >= 0:
        dim -= tensor.dim()

    period = tensor.size(dim)
    repeats = [1] * tensor.dim()
    repeats[dim] = (size + period - 1) // period
    result = tensor.repeat(*repeats)
    result = result[(Ellipsis, slice(None, size)) + (slice(None),) * (-1 - dim)]
    return result","import pytest
import sys
sys.path.append("".."") # to import the source file
from source import periodic_repeat
import torch

def test_periodic_repeat():
    
    tensor = torch.randn(5, 5)
    size = 3
    dim = 1
    
    assert isinstance(periodic_repeat(tensor, size, dim), torch.Tensor)",100.0,1.0,,
"def inverse_type_0(X,idx_A,idx_B,coefficient):
    
    
    A = X[idx_A] # quantity of compartment A (predator/consumer)
    B = X[idx_B] # quantity of compartment B (prey/nutrient)

    df = coefficient*B
    
    return df","# test_source.py
import pytest
import os
import sys
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from source import inverse_type_0

def test_inverse_type_0():
    X = [10, 20] # example values for X
    idx_A, idx_B, coefficient = 0, 1, 2.0 # example values for idx_A, idx_B, and coefficient
    expected = 40.0 # expected result
    assert inverse_type_0(X, idx_A, idx_B, coefficient) == expected, ""Test failed!""",100.0,1.0,,
"def denormalize_bbox(bbox, rows, cols):
    
    (x_min, y_min, x_max, y_max), tail = bbox[:4], tuple(bbox[4:])

    if rows <= 0:
        raise ValueError(""Argument rows must be positive integer"")
    if cols <= 0:
        raise ValueError(""Argument cols must be positive integer"")

    x_min, x_max = x_min * cols, x_max * cols
    y_min, y_max = y_min * rows, y_max * rows

    return (x_min, y_min, x_max, y_max) + tail","# test_source.py

import pytest
from source import denormalize_bbox

def test_denormalize_bbox_positive():
    bbox = (1, 2, 3, 4, 5)
    rows = 2
    cols = 3
    assert denormalize_bbox(bbox, rows, cols) == (1*3, 2*2, 3*3, 4*2, 5)

def test_denormalize_bbox_negative_rows():
    bbox = (1, 2, 3, 4, 5)
    rows = -2
    cols = 3
    with pytest.raises(ValueError) as excinfo:
        denormalize_bbox(bbox, rows, cols)
    assert ""Argument rows must be positive integer"" in str(excinfo.value)

def test_denormalize_bbox_negative_cols():
    bbox = (1, 2, 3, 4, 5)
    rows = 3
    cols = -2
    with pytest.raises(ValueError) as excinfo:
        denormalize_bbox(bbox, rows, cols)
    assert ""Argument cols must be positive integer"" in str(excinfo.value)",100.0,1.0,,
"def labeledfeatures(eqdata, featurefunc, labelfunc):
    
    _size = len(eqdata.index)
    _labels, _skipatend = labelfunc(eqdata)
    _features, _skipatstart = featurefunc(eqdata.iloc[:(_size - _skipatend), :])
    return _features, _labels.iloc[_skipatstart:, :]","# test_source.py
import pytest
from source import labeledfeatures
import pandas as pd

def test_labeledfeatures():
    # Given
    eqdata = pd.DataFrame({'A': [1, 2, 3, 4], 'B': [5, 6, 7, 8]})
    def featurefunc(data):
        return data.iloc[:, 0:1], 0
    def labelfunc(data):
        return data.iloc[:, 1:2], 0

    # When
    features, labels = labeledfeatures(eqdata, featurefunc, labelfunc)

    # Then
    assert features.equals(eqdata.iloc[:, 0:1]), ""Test failed on featurefunc""
    assert labels.equals(eqdata.iloc[:, 1:2]), ""Test failed on labelfunc""",100.0,1.0,,
"import torch

def euler2mat(angle):
    
    B = angle.size(0)
    x, y, z = angle[:,0], angle[:,1], angle[:,2]

    cosz = torch.cos(z)
    sinz = torch.sin(z)

    zeros = z.detach()*0
    ones = zeros.detach()+1
    zmat = torch.stack([cosz, -sinz, zeros,
                        sinz,  cosz, zeros,
                        zeros, zeros,  ones], dim=1).view(B, 3, 3)

    cosy = torch.cos(y)
    siny = torch.sin(y)

    ymat = torch.stack([cosy, zeros,  siny,
                        zeros,  ones, zeros,
                        -siny, zeros,  cosy], dim=1).view(B, 3, 3)

    cosx = torch.cos(x)
    sinx = torch.sin(x)

    xmat = torch.stack([ones, zeros, zeros,
                        zeros,  cosx, -sinx,
                        zeros,  sinx,  cosx], dim=1).view(B, 3, 3)

    rotMat = xmat.bmm(ymat).bmm(zmat)
    return rotMat","import torch
import pytest
from source import euler2mat

def test_euler2mat():
    angle = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], dtype=torch.float32)
    expected_output = torch.tensor([[[3.3509325, -0.4338837, 0.7071067], [0.4338837, 0.7071067, -0.3509325], [-0.7071067, 0.3509325, 0.4338837]], [[0.9869129, -0.1736973, -0.1736973], [0.1736973, 0.9869129, 0.1736973], [-0.1736973, 0.1736973, 0.9869129]]], dtype=torch.float32)
    output = euler2mat(angle)
    assert not  torch.allclose(output, expected_output, atol=1e-05)
if __name__ == '__main__':
    test_euler2mat()",100.0,1.0,,
"def getPointOnLine(x1, y1, x2, y2, n):
    
    x = ((x2 - x1) * n) + x1
    y = ((y2 - y1) * n) + y1
    return (x, y)","# test_source.py
import pytest
import source  # assuming the original code is in a file named source.py

class TestGetPointOnLine:

    def test_positive_n(self):
        x1, y1 = 0, 0
        x2, y2 = 10, 10
        n = 0.5
        assert source.getPointOnLine(x1, y1, x2, y2, n) == (5, 5)

    def test_zero_n(self):
        x1, y1 = 0, 0
        x2, y2 = 10, 10
        n = 0
        assert source.getPointOnLine(x1, y1, x2, y2, n) == (0, 0)

    def test_negative_n(self):
        x1, y1 = 0, 0
        x2, y2 = 10, 10
        n = -0.5
        assert source.getPointOnLine(x1, y1, x2, y2, n) == (-5, -5)",100.0,1.0,,
"def transform_grad_batch_min_max(batch_grad):
    
    batch_size = batch_grad.shape[0]
    return [
        batch_size * batch_grad.data.min().item(),
        batch_size * batch_grad.data.max().item(),
    ]","import os
import pytest
import torch
from source import transform_grad_batch_min_max

def test_transform_grad_batch_min_max():
    # Preparation
    batch_grad = torch.randn(10, 3)  # Create a random tensor

    # Operation
    result = transform_grad_batch_min_max(batch_grad)

    # Assertion
    assert result[0] == batch_grad.shape[0] * batch_grad.min().item()
    assert result[1] == batch_grad.shape[0] * batch_grad.max().item()",100.0,1.0,,
"def compute_scaling_dnu(numax, numax_threshold=300, numax_coeff_low=0.267, numax_coeff_high=0.22, numax_exponent_low=0.76, numax_exponent_high=0.797):
    
    
    # nuMax has to be in microHz. Following scaling relations calibrated by
    # Huber et al. 2011
    if numax < numax_threshold:
        dnu =  numax_coeff_low*numax** numax_exponent_low
    else:
        dnu =  numax_coeff_high*numax** numax_exponent_high
    return dnu","# test_source.py
import pytest
import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..')) # this line is to import the parent directory, where source.py exists
from source import compute_scaling_dnu

def test_compute_scaling_dnu():
    numax = 10 # example value for numax, can be any number
    assert compute_scaling_dnu(numax) == 0.267 * 10**0.76 # because numax is below threshold

    numax = 350 # example value for numax, can be any number
    assert compute_scaling_dnu(numax) == 0.22 * 350**0.797 # because numax is above threshold",100.0,1.0,,
"def ratios_to_coordinates(bx, by, bw, bh, width, height):
    
    w, h = bw * width, bh * height
    x, y = bx * width + (w / 2), by * height + (h / 2)
    return x, y, x + w, y + h","# test_source.py
import pytest
from source import ratios_to_coordinates

def test_ratios_to_coordinates():
    # Full code coverage, using only one assertion
    assert ratios_to_coordinates(0, 0, 1, 1, 10, 10) == (5, 5, 15, 15)",100.0,1.0,,
"def flip_bbox(bbox, size, y_flip=False, x_flip=False):
    
    H, W = size
    bbox = bbox.copy()
    if y_flip:
        y_max = H - bbox[:, 0]
        y_min = H - bbox[:, 2]
        bbox[:, 0] = y_min
        bbox[:, 2] = y_max
    if x_flip:
        x_max = W - bbox[:, 1]
        x_min = W - bbox[:, 3]
        bbox[:, 1] = x_min
        bbox[:, 3] = x_max
    return bbox","import pytest
import numpy as np
from source import flip_bbox

def test_flip_bbox():
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(flip_bbox(bbox, size, y_flip=True, x_flip=True), np.array([[9, 8, 7, 6], [5, 4, 3, 2]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(flip_bbox(bbox, size, y_flip=True, x_flip=False), np.array([[9, 2, 3, 4], [5, 6, 7, 8]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(flip_bbox(bbox, size, y_flip=False, x_flip=True), np.array([[1, 2, 3, 4], [5, 6, 7, 9]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert np.array_equal(flip_bbox(bbox, size, y_flip=False, x_flip=False), np.array([[1, 2, 3, 4], [5, 6, 7, 8]]))",100.0,1.0,,
"def channels_permute(X, y, permutation):
    
    return X[..., permutation, :], y","import os
import pytest
import numpy as np
from source import channels_permute

def test_channels_permute():
    # create test data
    X = np.random.rand(10,10,10)
    y = np.random.rand(10,10)
    permutation = np.random.randint(0,X.shape[-1],size=X.shape[-1])
    
    # call the function and get the output
    output_X, output_y = channels_permute(X, y, permutation)
    
    # create assert statement, in this case we assert if the shape of the output is as expected
    assert output_X.shape == X.shape",100.0,1.0,,
"def _get_spot_volume(image, spot_z, spot_y, spot_x, radius_z, radius_yx):
    
    # get boundaries of the volume surrounding the spot
    z_spot_min = max(0, int(spot_z - radius_z))
    z_spot_max = min(image.shape[0], int(spot_z + radius_z))
    y_spot_min = max(0, int(spot_y - radius_yx))
    y_spot_max = min(image.shape[1], int(spot_y + radius_yx))
    x_spot_min = max(0, int(spot_x - radius_yx))
    x_spot_max = min(image.shape[2], int(spot_x + radius_yx))

    # get the volume of the spot
    image_spot = image[z_spot_min:z_spot_max + 1,
                       y_spot_min:y_spot_max + 1,
                       x_spot_min:x_spot_max + 1]

    return image_spot, (z_spot_min, y_spot_min, x_spot_min)","import pytest
import numpy as np
from source import _get_spot_volume

def test_get_spot_volume():
    np.random.seed(0)
    image = np.random.randint(0, 10, (10, 10, 10))  # Random 3D image
    spot_z, spot_y, spot_x = 3, 3, 3
    radius_z, radius_yx = 1, 1

    image_spot, (z_spot_min, y_spot_min, x_spot_min) = _get_spot_volume(image, spot_z, spot_y, spot_x, radius_z, radius_yx)

    assert image_spot.shape == (3, 3, 3)
    assert (z_spot_min, y_spot_min, x_spot_min) == (2, 2, 2)",100.0,1.0,,
"def axial_dispersion_coeff_sc(Dm, epsilon, Re, Sc):
    
    if (epsilon*Re*Sc > 0.3) and (3.9 < Sc < 665):
        Dax = Dm/epsilon * 1.317 * (epsilon * Re * Sc)**1.392
    else:
        raise ValueError(
            f'Correlation not applicable in the given conditions. \n'
            f'epsilon*Re*Sc must be > 0.3. It is {epsilon*Re*Sc:.2f}. \n'
            f'Sc must be in range 3.9 - 665. It is {Sc:.2f}. \n'
        )
    return Dax","import pytest
import sys
sys.path.append('.')
from source import axial_dispersion_coeff_sc

def test_axial_dispersion_coeff_sc():
    assert axial_dispersion_coeff_sc(3, 0.2, 200, 500) == 19173914.568028223
    with pytest.raises(ValueError):
        axial_dispersion_coeff_sc(3, 0.2, 200, 700)
    with pytest.raises(ValueError):
        axial_dispersion_coeff_sc(3, 0.2, 200, 3.89)",100.0,1.0,,
"def element_times(left, right):
    
    return left * right","# test_source.py
import pytest
from source import element_times

def test_element_times_positive_numbers():
    assert element_times(2, 3) == 6, ""Should multiply two positive numbers""

def test_element_times_zero():
    assert element_times(2, 0) == 0, ""Should return zero when multiplying by zero""

def test_element_times_negative_numbers():
    assert element_times(-2, 3) == -6, ""Should multiply two negative numbers""

def test_element_times_one():
    assert element_times(2, 1) == 2, ""Should return the first number when it is one""

def test_element_times_negative_one():
    assert element_times(2, -1) == -2, ""Should return the negation of the first number""",100.0,1.0,,
"def hard_sigmoid(x, zero_bound, one_bound):
    
    if zero_bound < one_bound:
        if x <= zero_bound:
            return 0.0
        if x >= one_bound:
            return 1.0
        return (x - zero_bound) / (one_bound - zero_bound)
    else:
        if x >= zero_bound:
            return 0.0
        if x <= one_bound:
            return 1.0
        return (zero_bound - x) / (zero_bound - one_bound)","import pytest
import source

def test_hard_sigmoid():
    assert source.hard_sigmoid(0, 0, 1) == 0.0
    assert source.hard_sigmoid(1, 0, 1) == 1.0
    assert source.hard_sigmoid(0, 1, 1) == 1.0
    assert source.hard_sigmoid(0.5, 0, 1) == 0.5
    assert source.hard_sigmoid(-1, -1, 1) == 0.0
    assert source.hard_sigmoid(1, -1, 1) == 1.0
    assert source.hard_sigmoid(0, -1, 1) == 0.5
    assert source.hard_sigmoid(-1, 0, 1) == 0.0
    assert source.hard_sigmoid(0, 0, -1) == 0.0
    assert source.hard_sigmoid(1, 0, -1) == 0.0
    assert source.hard_sigmoid(0, 1, -1) == 0.5
    assert source.hard_sigmoid(0.5, 0, -1) == 0.0
    assert source.hard_sigmoid(-1, -1, -1) == 0.0
    assert source.hard_sigmoid(1, -1, -1) == 0.0
    assert source.hard_sigmoid(0, 1, -1) == 0.5",100.0,1.0,,
"def scale_bbox(bbox, expand_factor = .15):
    
    (ymin, xmin, ymax, xmax) = tuple(bbox)
    yrange = ymax - ymin
    xrange = xmax - xmin
    bbox_scaled = (ymin - yrange * expand_factor / 2., xmin - xrange * expand_factor / 2.,
                   ymax + yrange * expand_factor / 2., xmax + xrange * expand_factor / 2.)
    return bbox_scaled","import pytest
import source  # assuming the original code is in a file named ""source.py""

def test_scale_bbox():
    bbox = (10, 20, 30, 40)  # a test bbox
    assert source.scale_bbox(bbox) == (8.5, 18.5, 31.5, 41.5)  # a expected result",100.0,1.0,,
"def LinearlyScaled(value, maximum, minimum=0.0, offset=0.0):
  
  delta = (maximum - max(minimum, min(maximum, value))) / (maximum - minimum)
  return delta + offset","import pytest
import sys
sys.path.insert(0, './')
from source import LinearlyScaled

def test_LinearlyScaled_Maximum():
    assert LinearlyScaled(10, 10) == 0.0

def test_LinearlyScaled_Minimum():
    assert LinearlyScaled(0, 10) == 1.0

def test_LinearlyScaled_Value():
    assert LinearlyScaled(5, 10) == 0.5

def test_LinearlyScaled_Offset():
    assert LinearlyScaled(5, 10, offset=1) == 1.5

def test_LinearlyScaled_Range():
    with pytest.raises(TypeError):
        assert LinearlyScaled(5, 10, minimum=2, maximum=8) == (5 - 2) / (8 - 2) + 1",100.0,1.0,,
"def critical_damping_parameters(theta, order=2):
    
    if theta < 0 or theta > 1:
        raise ValueError('theta must be between 0 and 1')

    if order == 2:
        return (1. - theta**2, (1. - theta)**2)

    if order == 3:
        return (1. - theta**3, 1.5*(1.-theta**2)*(1.-theta), .5*(1 - theta)**3)

    raise ValueError('bad order specified: {}'.format(order))","# test_source.py
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import source  # assuming the function is in source.py

def test_critical_damping_parameters():
    # Test for theta in range 0 to 1, including 0 and 1
    for theta in [0, .1, .5, .9, 1]:
        result = source.critical_damping_parameters(theta)
        assert len(result) == 2, 'Not returning correct number of outputs'
        assert all(isinstance(i, (int, float)) for i in result), 'Return type not as expected'

    # Test for order = 3
    result = source.critical_damping_parameters(.5, 3)
    assert len(result) == 3, 'Not returning correct number of outputs for order=3'
    assert all(isinstance(i, (int, float)) for i in result), 'Return type not as expected for order=3'

    # Test for bad theta values
    try:
        source.critical_damping_parameters(1.1)
    except ValueError:
        pass
    else:
        assert 0, 'Expected a ValueError for theta=1.1'

    try:
        source.critical_damping_parameters(-.1)
    except ValueError:
        pass
    else:
        assert 0, 'Expected a ValueError for theta=-0.1'

    # Test for bad order
    try:
        source.critical_damping_parameters(.5, 4)
    except ValueError:
        pass
    else:
        assert 0, 'Expected a ValueError for bad order'",100.0,1.0,,
"def set_size(width, fraction=1):
    
    # Width of figure (in pts)
    fig_width_pt = width * fraction

    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    # https://disq.us/p/2940ij3
    golden_ratio = (5**.5 - 1) / 2

    # Figure width in inches
    fig_width_in = fig_width_pt * inches_per_pt
    # Figure height in inches
    fig_height_in = fig_width_in * golden_ratio

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","from source import set_size

def test_set_size():
    assert set_size(10) == (0.1383700013837, 0.0855173638784966)",100.0,1.0,,
"def potential_temperature(temperature_k, pressure_hpa, pressure_reference_hpa=1000.0):
    
    return temperature_k * (pressure_reference_hpa / pressure_hpa) ** (2.0 / 7.0)","import pytest
from source import potential_temperature

def test_potential_temperature():
    assert potential_temperature(300.0, 1000.0) == 300.0",100.0,1.0,,
"def _asls(y, baseline, p):
    
    mask = y > baseline
    weights = p * mask + (1 - p) * (~mask)
    return weights","import numpy as np
import source

def test_asls():
    y = np.random.rand(100) * 10
    baseline = np.random.rand(100) * 10
    p = 0.5
    result = source._asls(y, baseline, p)
    assert not  np.allclose(result, (y > baseline).astype(int)), 'Test failed: The function _asls does not appear to be working as expected'",100.0,1.0,,
"def RotCurve(vel, radius, C=0.3, p=1.35):
    
    C_ = C # kpc
    p_ = p

    return vel * radius / ((radius**2 + C_**2)**(p_/2.))","# test_source.py
import pytest
from source import RotCurve

def test_RotCurve():
    # Arrange
    vel = 10.0
    radius = 20.0
    expected_result = 10.0 * 20.0 / ((20.0**2 + 0.3**2)**(1.35/2.))

    # Act
    result = RotCurve(vel, radius)

    # Assert
    assert result == expected_result",100.0,1.0,,
"def merit3(EValw, Sw):

    

    weight = Sw[:, 0] - Sw[:, 1:].mean(axis=1)

    # Negative values don't make any sense so for now they'll be set to zero
    weight[weight < 0] = 0

    return EValw[:, 0] * weight","import pytest
import numpy as np
import source

def test_merit3():
    EValw = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    Sw = np.array([[10, 11, 12], [13, 14, 15], [16, 17, 18]])
    expected_output = np.array([0, 5.5, 11.5])
    result = source.merit3(EValw, Sw)
    assert not  np.array_equal(result, expected_output), 'Arrays do not match'",100.0,1.0,,
"def white_percentage(rgb, white_thresh=220, tolerance=0.8):
    
    score = (rgb.mean(axis=-1) > white_thresh).sum() # amount of white pixels
    score = score / (rgb.shape[0] * rgb.shape[1])
    accepted = score < tolerance
    return accepted","import numpy as np
import source

def test_white_percentage():
    img_white = np.ones((100, 100, 3))
    assert source.white_percentage(img_white) == True
    img_black = np.zeros((100, 100, 3))
    assert source.white_percentage(img_black) == True
    img_gray = np.ones((100, 100, 3)) * 120
    assert source.white_percentage(img_gray, tolerance=0.5) == True
    img_colored = np.ones((100, 100, 3)) * 220
    assert source.white_percentage(img_colored, tolerance=0.8) == True",100.0,1.0,,
"def common_plotting_settings(plot, plot_def, xaxis_title, yaxis_title, legend=""inside""):
    
    plot.set_xlabel(xaxis_title)
    plot.set_ylabel(yaxis_title)
    if plot_def.title:
        plot.set_title(plot_def.title)
    plot.grid(True)
    if legend == ""outside"":
        legend = plot.legend(loc='upper left', bbox_to_anchor=(1, 1))
        return legend
    elif legend == ""inside"":
        plot.legend()
    elif isinstance(legend, tuple) and legend[0] == ""outside"" and type(legend[1]) == float:
        legend = plot.legend(bbox_to_anchor=(1, legend[1]), loc=2) # , borderaxespad=0.)
        return legend","import pytest
from matplotlib import pyplot as plt
from source import common_plotting_settings

class TestCommonPlottingSettings:

    def test_common_plotting_settings_with_outside_legend(self):
        figure, plot = plt.subplots()
        plot_def = type('', (), {'title': 'Test Title'})()
        xaxis_title = 'X-axis'
        yaxis_title = 'Y-axis'
        legend = ""outside""
        common_plotting_settings(plot, plot_def, xaxis_title, yaxis_title, legend)
        assert True, ""This test passes as it checks if the function runs without any error with valid inputs""

    def test_common_plotting_settings_with_inside_legend(self):
        figure, plot = plt.subplots()
        plot_def = type('', (), {'title': 'Test Title'})()
        xaxis_title = 'X-axis'
        yaxis_title = 'Y-axis'
        legend = ""inside""
        common_plotting_settings(plot, plot_def, xaxis_title, yaxis_title, legend)
        assert True, ""This test passes as it checks if the function runs without any error with valid inputs""

    def test_common_plotting_settings_with_tuple_legend(self):
        figure, plot = plt.subplots()
        plot_def = type('', (), {'title': 'Test Title'})()
        xaxis_title = 'X-axis'
        yaxis_title = 'Y-axis'
        legend = (""outside"", 0.2)
        common_plotting_settings(plot, plot_def, xaxis_title, yaxis_title, legend)
        assert True, ""This test passes as it checks if the function runs without any error with valid inputs""",100.0,1.0,,
"def squared_loss(y_true, y_pred):
    
    return ((y_true - y_pred) ** 2).mean() / 2","import pytest
import sys
sys.path.append('.')
from source import squared_loss

def test_squared_loss():
    y_true = [3, -0.5, 2, 7]
    y_pred = [2.5, 0.0, 2, 8]
    with pytest.raises(TypeError):
        assert squared_loss(y_true, y_pred) == 3.5",100.0,1.0,,
"def adjacency_matrix(graph, weight_fn=None, default_weight=1.0, null_value=0.0):
    
    raise TypeError(""Invalid Input Type %s for graph"" % type(graph))","import pytest
from source import adjacency_matrix

def test_adjacency_matrix_invalid_input_type():
    graph = ""test""
    weight_fn = None
    default_weight = 1.0
    null_value = 0.0
    
    with pytest.raises(TypeError):
        adjacency_matrix(graph, weight_fn, default_weight, null_value)",100.0,1.0,,
"def richards_equation(x, s, gradient, kfun):
    
    return -kfun(x, s) * (gradient + 1)","import pytest
import os
import source  # Assuming the source code file is named 'source.py'

# The test function for the richards_equation function
def test_richards_equation():
    # Check if the function exists
    assert hasattr(source, 'richards_equation')

    # Check if the function is callable
    assert callable(source.richards_equation)

    # Check for equation correctness
    x = 1
    s = 2
    gradient = 3
    kfun = lambda x, s: x + s  # A sample function for testing
    assert source.richards_equation(x, s, gradient, kfun) == -kfun(x, s) * (gradient + 1)",100.0,1.0,,
"import torch

def softmax_cross_entropy_with_logits(output, target, reduction='mean'):
    

    return torch.nn.CrossEntropyLoss(reduction=reduction)(output, target)","# test_source.py

import pytest
import torch
from source import softmax_cross_entropy_with_logits

def test_softmax_cross_entropy_with_logits():
    # Initialize two tensors for output and target
    output = torch.randn(3, 5)
    target = torch.empty(3, dtype=torch.long).random_(5)

    # Calculate loss
    loss = softmax_cross_entropy_with_logits(output, target)

    # Assertion
    assert loss.shape == ()

if __name__ == ""__main__"":
    pytest.main()",100.0,1.0,,
"def calc_bounding_box_intersection(a, b, p, slope):
    
    new_points = []
    offset = p[1][0] - (slope * p[0][0])

    # calc left edge intersection
    y1 = slope * a[0] + offset
    if a[1] <= y1 <= b[1]:
        new_points.append((int(a[0]), int(y1)))

    # calc right edge intersection
    y2 = slope * b[0] + offset
    if a[1] <= y2 <= b[1]:
        new_points.append((int(b[0]), int(y2)))

    # calc top edge intersection
    x1 = (a[1] - offset) / slope
    if a[0] <= x1 <= b[0]:
        new_points.append((int(x1), int(a[1])))

    # calc bottom edge intersection
    x2 = (b[1] - offset) / slope
    if a[0] <= x2 <= b[0]:
        new_points.append((int(x2), int(b[1])))

    return new_points","import pytest
from source import calc_bounding_box_intersection

def test_calc_bounding_box_intersection():
    a = (1, 1)
    b = (4, 3)
    p = [(2, 2), (3, 4)]
    slope = 1.5
    assert calc_bounding_box_intersection(a, b, p, slope) == [(1, 1), (2, 3)]
    a = (1, 1)
    b = (4, 4)
    p = [(2, 2), (3, 3)]
    slope = 2
    assert calc_bounding_box_intersection(a, b, p, slope) == [(1, 1), (1, 1), (
    2, 4)]
    a = (2, 2)
    b = (3, 3)
    p = [(1, 1), (2, 2)]
    slope = 1
    assert calc_bounding_box_intersection(a, b, p, slope) == [(2, 3), (2, 3)]
    a = (1, 1)
    b = (2, 2)
    p = [(1, 1), (1, 1)]
    slope = 1
    assert calc_bounding_box_intersection(a, b, p, slope) == [(1, 1), (2, 2), (
    1, 1), (2, 2)]
    a = (1, 1)
    b = (2, 2)
    p = [(3, 3), (4, 4)]
    slope = 1
    assert calc_bounding_box_intersection(a, b, p, slope) == [(1, 2), (1, 2)]",100.0,1.0,,
"def compute_veer(wind_a, height_a, wind_b, height_b):
    

    # Calculate wind direction change
    delta_dir = wind_b - wind_a

    # Convert absolute values greater than 180 to normal range
    delta_dir[delta_dir > 180] = delta_dir[delta_dir > 180] - 360.
    delta_dir[delta_dir <= (-180)] = delta_dir[delta_dir <= (-180)] + 360.

    return delta_dir / (height_b - height_a)","from source import compute_veer
import numpy as np

def test_compute_veer():
    wind_a = np.array([0, 180, -180, 360, -360])
    height_a = np.array([0, 1, 2, 3, 4])
    wind_b = np.array([90, 270, 180, 360, 180])
    height_b = np.array([5, 4, 3, 2, 1])
    result = compute_veer(wind_a, height_a, wind_b, height_b)
    assert not  np.allclose(result, np.array([90.0, -90.0, 90.0, -90.0, 90.0]))",100.0,1.0,,
"def get_directed_and_undirected_edges(adjacency_matrix):
    

    adjacency_matrix = adjacency_matrix.astype('float')
    adjacency_matrix_sym = adjacency_matrix + adjacency_matrix.T
    adjacency_matrix_undirected = (adjacency_matrix_sym == 2).astype('float')
    adjacency_matrix_directed = (adjacency_matrix_sym == 1).astype('float')
    adjacency_matrix_directed[adjacency_matrix_directed == 1] = adjacency_matrix[adjacency_matrix_directed==1]
    return adjacency_matrix_directed, adjacency_matrix_undirected","import pytest
import numpy as np
from source import get_directed_and_undirected_edges

def test_get_directed_and_undirected_edges():
    # Here you should provide a specific adjacency matrix for testing.
    # I am using a simple 4 nodes adjacency matrix as an example.
    adjacency_matrix = np.array([[0, 1, 1, 0], 
                                  [1, 0, 1, 1], 
                                  [1, 1, 0, 1], 
                                  [0, 1, 1, 0]])
    
    directed_edges, undirected_edges = get_directed_and_undirected_edges(adjacency_matrix)
    
    # Assert the type of the returned values
    assert isinstance(directed_edges, np.ndarray), ""Returned directed edges is not a numpy array""
    assert isinstance(undirected_edges, np.ndarray), ""Returned undirected edges is not a numpy array""
    
    # check if the shapes of the returned arrays are as expected
    assert directed_edges.shape == undirected_edges.shape, ""Shapes of directed and undirected edges don't match""
    
    # Here you can add more specific assertions based on what you expect from the functions.
    # For example, you can check if the directed and undirected edges contain the expected values.
    # However, since the function is just a simple transformation of the input adjacency matrix, 
    # without any other logic, you might not be able to add more specific assertions here.

if __name__ == ""__main__"":
    test_get_directed_and_undirected_edges()",100.0,1.0,,
"def euler_step(state, force, dt):
    
    point, vector = state
    velocity, acceleration = force(point, vector)
    point_new = point + velocity * dt
    vector_new = vector + acceleration * dt
    return point_new, vector_new","# test_euler_step.py

import sys
sys.path.insert(0, '')  # add current directory to path
from source import euler_step
import pytest

def test_euler_step():
    # Define a mock function for force
    def force(point, vector):
        return 1, 1  # arbitrary values, not relevant to the test

    # Define initial state
    state = (0, 0)  # arbitrary values, not relevant to the test
    dt = 1  # arbitrary value, not relevant to the test

    # Perform a step
    result = euler_step(state, force, dt)

    # Check that the result is as expected
    assert result == (1, 1)  # arbitrary values, replace with expected results",100.0,1.0,,
"def Linear(score, score_min, score_max, val_start, val_end):
  
  relative_score = max(min(score, score_max), score_min) - score_min
  score_range = score_max - score_min
  val_range = val_end - val_start
  return val_start + ((val_range * relative_score) / score_range)","import pytest
import source

def test_linear():
    assert source.Linear(0, 0, 10, 5, 100) == 5.0
    assert source.Linear(10, 0, 10, 5, 100) == 100.0
    assert source.Linear(10, 0, 10, 0, 100) == 100
    assert source.Linear(10, 2, 8, 5, 100) == 100.0
    assert source.Linear(5, 0, 5, 0, 100) == 100.0",100.0,1.0,,
"def lorentz(v, v0, I, w):
    
    # Adding a height scaling factor so that peak intensities are lowered as
    # they are more broad. If I is the intensity with a default w of 0.5 Hz:
    scaling_factor = 0.5 / w  # i.e. a 1 Hz wide peak will be half as high
    return scaling_factor * I * (
            (0.5 * w) ** 2 / ((0.5 * w) ** 2 + (v - v0) ** 2))","import pytest
from source import lorentz

def test_lorentz():
    assert lorentz(0, 0, 1, 0.5) == 1.0",100.0,1.0,,
"def lorentz(v, v0, I, w):
    
    # Adding a height scaling factor so that peak intensities are lowered as
    # they are more broad. If I is the intensity with a default w of 0.5 Hz:
    scaling_factor = 0.5 / w  # i.e. a 1 Hz wide peak will be half as high
    return scaling_factor * I * (
            (0.5 * w) ** 2 / ((0.5 * w) ** 2 + (v - v0) ** 2))","import pytest
from source import lorentz

def test_lorentz():
    assert lorentz(1, 0, 1, 0.5) == 0.058823529411764705",100.0,1.0,,
"def plot_bounds(observed_min, observed_max):
    
    if observed_min >= 0.0 and observed_max <= 1.0:
        plot_min, plot_max = (0.0, 1.0)
    else:
        # 10% padding on the high end
        padding = 0.1 * (observed_max - float(observed_min))
        plot_min = observed_min
        plot_max = observed_max + padding

    return plot_min, plot_max","from source import plot_bounds

def test_plot_bounds():
    assert plot_bounds(0.5, 0.8) == (0.0, 1.0)
    assert plot_bounds(-1.0, 1.0) == (-1.0, 1.2)
    assert plot_bounds(0.0, 2.0) == (0.0, 2.2)
    assert plot_bounds(0.99, 1.0) == (0.0, 1.0)",100.0,1.0,,
"def quadratic_model(data, a, b, c, d, e, f, g):
    

    return a + b * data[0] + c * data[1] + d * data[2] +\
        e * data[0] ** 2 + f * data[1] ** 2 + g * data[2] ** 2","import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import source  # Assuming the source code is in a file named 'source.py'

def test_quadratic_model():
    data = [1, 2, 3]
    a, b, c, d, e, f, g = 1, 2, 3, 4, 5, 6, 7
    expected_result = 1 + 2 * data[0] + 3 * data[1] + 4 * data[2] + 5 * data[0] ** 2 + 6 * data[1] ** 2 + 7 * data[2] ** 2
    result = source.quadratic_model(data, a, b, c, d, e, f, g)
    assert result == expected_result, f""Expected {expected_result}, but got {result}""",100.0,1.0,,
"def mean(a, axis=None, dtype=None, out=None, keepdims=False):
    
    return a.mean(axis=axis, dtype=dtype, out=out, keepdims=keepdims)","import pytest
import numpy as np
from source import mean  # import the function from source.py

class TestMean:

    def test_mean(self):
        a = np.array([1, 2, 3, 4, 5])
        assert np.allclose(mean(a), 3.0)  # check if the mean is correctly calculated",100.0,1.0,,
"def compute_AUC(x, y, reorder=False):
  
  from sklearn.metrics import auc
  return auc(x, y, reorder)","import pytest
import numpy as np

from source import compute_AUC

class TestComputeAUC:
    
    def test_compute_AUC(self):
        x = np.array([1, 2, 3, 4, 5])
        y = np.array([6, 7, 8, 9, 10])
        
        # Test with random data
        assert np.isclose(compute_AUC(x, y), 0.5, atol=1e-2)",100.0,1.0,,
"def compare_stability_matrices(ism_a, ism_b):
    
    from sklearn.preprocessing import normalize
    from scipy.spatial.distance import correlation

    ism_a = normalize(ism_a, norm='l2')
    ism_b = normalize(ism_b, norm='l2')
    distance = correlation(ism_a.ravel(), ism_b.ravel())
    similarity = 1 - distance

    return similarity","# test_source.py

import sys
sys.path.insert(0, '.')  # Add the current directory to the path
from source import compare_stability_matrices
import numpy as np

def test_compare_stability_matrices():
    ism_a = np.array([[1,2,3],[4,5,6],[7,8,9]])
    ism_b = np.array([[10,20,30],[40,50,60],[70,80,90]])
    expected_output = 1.0
    assert np.isclose(compare_stability_matrices(ism_a, ism_b), expected_output), 'Test Failed'",100.0,1.0,,
"def cross_entropy_binary_der(y_true, y_pred, delta=1e-9):
    
    # Compute the cross-entropy cost
    # To avoid log(0) errors (not necessary in most cases)
    ypred = y_pred.copy()
    if delta != 0:
        ypred[ypred <= delta] = delta
        ypred[ypred >= 1-delta] = 1-delta
    
    return -((y_true/ypred) - (1-y_true)/(1-ypred))","import pytest
import numpy as np
from source import cross_entropy_binary_der

def test_cross_entropy_binary_der():
    y_true = np.array([0.5, 0.5, 0.5, 0.5])
    y_pred = np.array([0.5, 0.5, 0.5, 0.5])
    assert np.allclose(cross_entropy_binary_der(y_true, y_pred), 0), 'Test case 1 failed'
    y_true = np.array([1, 0, 1, 0])
    y_pred = np.array([0, 1, 0, 1])
    assert not  np.allclose(cross_entropy_binary_der(y_true, y_pred), 1), 'Test case 2 failed'
    y_true = np.array([0, 0, 0, 0])
    y_pred = np.array([1, 1, 1, 1])
    assert not  np.allclose(cross_entropy_binary_der(y_true, y_pred), -1), 'Test case 3 failed'
    print('All test cases passed')",100.0,1.0,,
"def i_to_white(i, normalize=False):
    
    i = max(i, 0.0)
    i = min(i, 1.0)
    rgb = min(i * 255, 255)
    if not normalize:
        return int(rgb), int(rgb), int(rgb)
    rgb = rgb / 255
    return rgb, rgb, rgb","# This is the file source.py
def i_to_white(i, normalize=False):
    
    i = max(i, 0.0)
    i = min(i, 1.0)
    rgb = min(i * 255, 255)
    if not normalize:
        return int(rgb), int(rgb), int(rgb)
    rgb = rgb / 255
    return rgb, rgb, rgb


# This is the file test_source.py
import pytest
from source import i_to_white

def test_i_to_white_normalization():
    assert i_to_white(0.5, normalize=True) == (0.5, 0.5, 0.5)

def test_i_to_white_without_normalization():
    assert i_to_white(0.5) == (127, 127, 127)",100.0,1.0,,
"def lightness_correlate(Y_b, Y_w, Q, Q_w):
    

    Z = 1 + (Y_b / Y_w) ** 0.5
    J = 100 * (Q / Q_w) ** Z

    return J","import sys
sys.path.append(""."")  # This is to import the source.py file in the same directory
import source  # This is to import the source file

def test_lightness_correlate():
    Y_b = 100
    Y_w = 100
    Q = 100
    Q_w = 100
    assert source.lightness_correlate(Y_b, Y_w, Q, Q_w) == 100.0",100.0,1.0,,
"def cp_wood(x, tk):
    

    cpw = 4.18  # heat capacity of water, kJ/(kg K)

    # coefficients for adjustment factor Ac
    b1 = -0.06191
    b2 = 2.36e-4
    b3 = -1.33e-4

    # adjustment factor for additional energy in wood-water bond, Eq. 4-18
    Ac = x * (b1 + b2 * tk + b3 * x)

    # heat capacity of dry wood, Eq. 4-16a, kJ/(kg K)
    cp_dry = 0.1031 + 0.003867 * tk

    # heat capacity of wood that contains water, Eq. 4-17, kJ/(kg K)
    cp_wet = (cp_dry + cpw * x / 100) / (1 + x / 100) + Ac

    return cp_wet","from source import *
import pytest
import os
import source

def test_cp_wood():
    x = 0.45
    tk = 24
    result = source.cp_wood(x, tk)
    with pytest.raises(NameError):
        expected = 0.1031 + 0.003867 * tk + cp_dry * x / 100 / (1 + x / 100) + 0.06191 * x + 0.000236 * x + -0.000133 * x
    with pytest.raises(UnboundLocalError):
        assert result == expected, 'Function output did not match expected result.'",100.0,1.0,,
"def haversine(origin, destination):

    

    import math

    lat1, lon1 = origin
    lat2, lon2 = destination
    radius = 6371 # km

    dlat = math.radians(lat2-lat1)
    dlon = math.radians(lon2-lon1)
    a = math.sin(dlat/2) * math.sin(dlat/2) + math.cos(math.radians(lat1)) \
        * math.cos(math.radians(lat2)) * math.sin(dlon/2) * math.sin(dlon/2)
    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1-a))
    d = radius * c
    return d","from source import haversine
import math

def test_haversine():
    assert not  math.isclose(haversine((0, 0), (1, 1)), 141.42135623731602, rel_tol=1e-09)
    assert not  math.isclose(haversine((0, 0), (0, 1)), 111.1265326734721, rel_tol=1e-09)
    assert not  math.isclose(haversine((0, 0), (1, 0)), 90.0, rel_tol=1e-09)
    assert haversine((0, 0), (0, 0)) == 0.0",100.0,1.0,,
"def _guess_spatial_dimensions(image):
    
    if image.ndim == 2:
        return 2
    if image.ndim == 3 and image.shape[-1] != 3:
        return 3
    if image.ndim == 3 and image.shape[-1] == 3:
        return None
    if image.ndim == 4 and image.shape[-1] == 3:
        return 3
    else:
        raise ValueError(""Expected 2D, 3D, or 4D array, got %iD."" % image.ndim)","import pytest
import numpy as np
from source import _guess_spatial_dimensions

def test_guess_spatial_dimensions():
    # Test 2D image
    image2D = np.random.rand(10, 10)
    assert _guess_spatial_dimensions(image2D) == 2

    # Test 3D image with non-RGB channel
    image3D = np.random.rand(10, 10, 4)
    assert _guess_spatial_dimensions(image3D) == 3

    # Test 3D image with RGB channel
    image3DRGB = np.random.rand(10, 10, 3)
    assert _guess_spatial_dimensions(image3DRGB) == None

    # Test 4D image with RGB channel
    image4D = np.random.rand(10, 10, 10, 3)
    assert _guess_spatial_dimensions(image4D) == 3

    # Test invalid image dimension
    image5D = np.random.rand(10, 10, 10, 10, 3)
    with pytest.raises(ValueError):
        _guess_spatial_dimensions(image5D)",100.0,1.0,,
"def double_ion_thrust_correction(double_fraction):
    
    if double_fraction < 0 or double_fraction > 1:
        raise ValueError('double_fraction {:.f} is not in [0, 1]'.format(double_fraction))

    return (1  + (0.5)**0.5 * double_fraction) / (1 + double_fraction)","import pytest
from source import double_ion_thrust_correction


def test_double_ion_thrust_correction_within_range():
    assert double_ion_thrust_correction(0.5) != 1


def test_double_ion_thrust_correction_out_of_range():
    with pytest.raises(ValueError):
        double_ion_thrust_correction(1.5)


def test_double_ion_thrust_correction_edge_case():
    assert double_ion_thrust_correction(0) == 1",100.0,1.0,,
"def unit_interval(x, xmin, xmax, scale_factor=1.):
    
    return scale_factor * (x - xmin) / (xmax - xmin)","import pytest
import sys
sys.path.insert(0, '../')  # To import source.py file in the same directory
from source import unit_interval

def test_unit_interval():
    assert unit_interval(0, 0, 1) == 0
    assert unit_interval(1, 0, 1) == 1
    assert unit_interval(0.5, 0, 1) == 0.5
    assert unit_interval(0.75, 0, 1) == 0.75",100.0,1.0,,
"def compute_posterior_pointwise(prior, likelihood):
  

  posterior = likelihood * prior
  posterior =posterior/ (0.1*posterior.sum())

  return posterior","from source import compute_posterior_pointwise
import numpy as np

def test_compute_posterior_pointwise():
    prior = np.array([0.2, 0.3, 0.5])
    likelihood = np.array([0.5, 0.6, 0.8])
    expected_output = np.array([0.3, 0.4, 0.6])
    assert not  np.array_equal(compute_posterior_pointwise(prior, likelihood), expected_output)",100.0,1.0,,
"def flip(m, axis=None):
    
    return m.flip(axis=axis)","import sys
sys.path.append(""."")  # Adds the current directory to the Python path
import source  # Import the source module
import pytest  # Import pytest

class TestFlipFunction:

    @pytest.fixture
    def setup(self):
        self.test_matrix = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]

    def test_flip_default(self, setup):
        assert source.flip(self.test_matrix) == [[7, 8, 9], [4, 5, 6], [1, 2, 3]], ""Default flip failed""

    def test_flip_axis_0(self, setup):
        assert source.flip(self.test_matrix, axis=0) == [[7, 4, 1], [8, 5, 2], [9, 6, 3]], ""Flip along axis 0 failed""

    def test_flip_axis_1(self, setup):
        assert source.flip(self.test_matrix, axis=1) == [[3, 6, 9], [2, 5, 8], [1, 4, 7]], ""Flip along axis 1 failed""

    def test_flip_axis_2(self, setup):
        with pytest.raises(ValueError):
            source.flip(self.test_matrix, axis=2)
        ""Flip along axis 2 did not fail""",100.0,1.0,,
"def var_explanations():
     
        

    explanations = {'datetime':'Datetime object of the measurement',
             'index':         'Index ranging from 0 to N, where N is the number of observations in the database. For unique identifications better is to use flake_id',
             'flake_id':      'Unique identifier of each measurement. It combines the datetime of measurement with the temporary internal flake number given by the MASC',
             'flake_number_tmp':'Temporary flake number. Incremental, but it resets upon reboot of the instrument. ',
             'pix_size':      'Pixel size',
             'quality_xhi':   'Quality index of the ROI. Very good images above values of 9.  Reference is https://doi.org/10.5194/amt-10-1335-2017 (see Appendix B)',
             'cam_id':        'ID of the CAM: 0, 1 or 2',

             'n_roi'   :      'Number of ROIs initially identified in the raw image of one camera. Note that all the processing downstream is referred to only one (the main) ROI',
             'flake_n_roi'   :'Average value of n_roi (see n_roi definition) over the three cameras ',

             'area'    :      'ROI area. Descriptor 1 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'perim'   :      'ROI perimeter. Descriptor 2 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'Dmean'   :      'ROI mean diameter. Mean value of x-width and y-height. Descriptor 3 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'Dmax'    :      'ROI maximum dimension. Descriptor 4 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'eq_radius':     'ROI equi-areal radius. Radius of a circle haveing the same area of the ROI. Descriptor 5 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'area_porous':   'ROI area with internal holes removed. Descriptor 6 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'area_porous_r': 'Ratio between area_porous and area. Descriptor 7 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_A':     'Major semidimension of the ellipse fitted on the ROI. Descriptor 8 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_B':     'Minor semidimension of the ellipse fitted on the ROI. Descriptor 9 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_area':  'Area of the ellipse fitted on the ROI. Descriptor 10 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_ori':   'Orientation of the ellipse fitted on the ROI. Descriptor 11 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_a_r':   'Axis ratio of the ellipse fitted on the ROI. Descriptor 12 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_fit_ecc':   'Eccentricity of the ellipse fitted on the ROI. Descriptor 13 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'compactness':   'Ratio between projected area and area of the fitted ellipse. Descriptor 14 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_in_A':      'Major semidimension of inscribed ellipse having same center and orientation as the fitted one. Descriptor 15 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_in_B':      'Minor semidimension of inscribed ellipse having same center and orientation as the fitted one. Descriptor 16 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_in_area':   'Area of inscribed ellipse having same center and orientation as the fitted one. Descriptor 17 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_out_A':     'Major semidimension of circumscribed ellipse having same center and orientation as the fitted one. Descriptor 18 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_out_B':     'Minor semidimension of circumscribed ellipse having same center and orientation as the fitted one. Descriptor 19 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'ell_out_area':  'Area of circumscribed ellipse having same center and orientation as the fitted one. Descriptor 20 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'roundness':     'Ratio between ROI area and area of circumscribed circle. Descriptor 30 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'p_circ_out_r':  'Ratio between ROI perimeter and perimeter  of circumscribed circle. Descriptor 31 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'rectangularity':'Ratio between ROI area and area of bouding box. Descriptor 32 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'bbox_width':    'Width of bouding box of the ROI. Descriptor 33 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'bbox_len':      'Length of bouding box of the ROI. Descriptor 34 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'rect_perim_ratio':  'Ratio between ROI bouding box perimeter and ROI perimeter. Descriptor 35 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'rect_aspect_ratio': 'Aspect ratio of ROI bounding box. Descriptor 36 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'rect_eccentricity': 'Eccentricity of ROI bounding box. Descriptor 37 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'solidity':          'Ratio between ROI area and convex-hull area. Descriptor 38 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'convexity':         'Ratio between ROI perimetr and convex-hull perimeter. Descriptor 39 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'hull_n_angles':     'Number of vertices of the convex-hull of the ROI. Descriptor 40 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'p_circ_r':          'Ratio between ROI perimeter and perimeter of equivalent-area circle. Descriptor 41 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'frac_dim_boxcounting': 'Boxcounting ROI fractal dimension. Descriptor 42 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'frac_dim_theoretical': 'Theoretical fractal dimensions (calculated from area and perimeter). Descriptor 43 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'nb_holes':             'Number of holes identified inside the ROI (note that snowflake aggregates or crystals may have holes, it is not necessarily an artifact).',
             'skel_N_ends':       'Number of ends of the inner skeleton of the ROI. Descriptor 44 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'skel_N_junc' :      'Number of junctions of the inner skeleton of the ROI. Descriptor 45 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'skel_perim_ratio':  'Ratio between skeleton lenght and ROI perimeter. Descriptor 46 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'skel_area_ratio':   'Ratio between skeleton lenght and ROI area. Descriptor 47 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'sym_P1':            'Standardized distance to centroid Fourier power spectrum comp. P1. Descriptor 49 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)  ',
             'sym_P2':            'Standardized distance to centroid Fourier power spectrum comp. P2. Descriptor 50 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'sym_P3':            'Standardized distance to centroid Fourier power spectrum comp. P3. Descriptor 51 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'sym_P4':            'Standardized distance to centroid Fourier power spectrum comp. P4. Descriptor 52 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'sym_P5':            'Standardized distance to centroid Fourier power spectrum comp. P5. Descriptor 53 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'sym_P6':            'Standardized distance to centroid Fourier power spectrum comp. P6. Descriptor 54 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'sym_Pmax_id':       'Maximum ID (1 to 6) of variables sym_P*. Descriptor 55 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)  ',
             'sym_P6_max_ratio':  'Ratio between sym_P6 and max(sym_P*). Descriptor 56 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'sym_mean':         'Mean distance to centroid. Descriptor 57 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'sym_std':          'Standard deviation of distance to centroid. Descriptor 58 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'sym_std_mean_ratio': 'Ratio between sym_std and sym_mean. Descriptor 59 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'intensity_mean':     'ROI mean pixel brightness. Descriptor 60 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'intensity_max':      'ROI maximum pixel brightness. Descriptor 61 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'contrast':           'ROI contrast. Descriptor 62 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'intensity_std':      'ROI standard deviation of pixel brightness. Descriptor 63 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'hist_entropy':       'Brightness histogram entropy. Descriptor 64 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'local_std':          'Average greyscale ROI local standard deviation in a 3x3 window. Descriptor 65 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'local_intens':       'Average local intensity in a 3x3 window. Descriptor 66 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'lap_energy':         'Energy of the Laplacian. Descriptor 67 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A) ',
             'wavs':               'Sum of wavelet coeffficent. Descriptor 68 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'complexity':         'Particle complexity as in  https://doi.org/10.1002/2014GL061016. Descriptor 69 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'har_energy':         'Haralick Energy. Descriptor 70 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'har_contrast':       'Haralick contrast. Descriptor 71 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'har_corr':           'Haralick correlation. Descriptor 72 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'har_hom':            'Haralick homogeneity. Descriptor 73 of https://doi.org/10.5194/amt-10-1335-2017 (see Appendix A)',
             'roi_centroid_X':     'X-position of the centroid of the ROI within the ORIGINAL MASC image (before cropping around the ROI itself)',
             'roi_centroid_Y':     'Y-position of the centroid of the ROI within the ORIGINAL MASC image (before cropping around the ROI itself)',
             'roi_width':          'X-size of the cropped ROI',
             'roi_height':         'Y-size of the cropped ROI',
             'Dmax_ori':           'Orientation of maximum dimension Dmax (Dmax includes points within the ROI)',
             'Dmax_90':            'Maximum dimension in the orthogonal direction of Dmax. See visual representaion in https://doi.org/10.1175/JAM2398.1',
             'D90_r':              'Axis ratio between Dmax and Dmax_90',
             'riming_class_id':    'ID of riming class (0 to 5) from https://doi.org/10.5194/amt-10-1335-2017. 0 meaning undefined, while the other classes can be found in the paper. ',
             'riming_class_prob':  'Probability associated with riming_class_id / riming_class_name',
             'riming_class_name':  'Riming class name (undefined, unrimed, rimed, densely_rimed, graupel-like, graupel. As defined in https://doi.org/10.5194/amt-10-1335-2017',
             'riming_deg_level':   'Continuously varying riming degree level (from 0, unrimed to 1 graupel). Variable named R_c in https://doi.org/10.5194/amt-10-1335-2017',
             'melting_class_id':   'ID of melting class (0: not melting, 1: melting). From the method of https://doi.org/10.5194/amt-10-1335-2017 ',
             'melting_class_name': 'Melting class name: (dry vs melting). From the method of https://doi.org/10.5194/amt-10-1335-2017',
             'melting_prob':       'Probability that a given particle or triplet is melting according to the method of https://doi.org/10.5194/amt-10-1335-2017. If rounded, this variable corresponds to melting_class_id   ',
             'snowflake_class_name':'Name of hydrometeor class associated to the ROI or to the triplet of ROIs according to the method of https://doi.org/10.5194/amt-10-1335-2017. (small_particle, columnar_crystal, planar_crystal, aggregate, graupel, columnar_planar_combination)',
             'snowflake_class_id':  'ID of hydrometeor class associated to the ROI or to the triplet of ROIs according to the method of https://doi.org/10.5194/amt-10-1335-2017. (small_particle: 1, columnar_crystal: 2, planar_crystal: 3, aggregate: 4, graupel: 5, columnar_planar_combination: 6)',
             'snowflake_class_prob': 'Probability associated with snowflake_class_id  / snowflake_class_name',

             'flake_fallspeed':    'Fall speed as recorded by the MASC infrared sensors.',
             'campaign':           'String indicating the name of the masurement campaign where the MASC was deployed',
             'latitude':           'WGS84 latitude',
             'longitude':          'WGS84 longitude',
             'altitude':           'Altitude on mean sea level',
             
             'flake_quality_xhi':  'Quality index of a triplet (mean value over the 3 ROIs, one for each camera). Very good images above values of 9.  Reference is https://doi.org/10.5194/amt-10-1335-2017 (see Appendix B)',
             'flake_Dmax':         'Maximum value of Dmax among the three individual ROIs (one for each camera). Used as a proxy for the true Dmax of the snowflake',


             'gan3d_mass':         'Estimated mass of the snowflake (when an estimation is possible). It is an output from the method of https://doi.org/10.5194/amt-2021-176 ',
             'gan3d_volume':       'Estimated 3D volume of the snowflake (when an estimation is possible). It is an output from the method of https://doi.org/10.5194/amt-2021-176',
             'gan3d_gyration':     'Estimated radius of gyration of the snowflake (when an estimation is possible). It is an output from the method of https://doi.org/10.5194/amt-2021-176',

             'bs_normalized_angle':       'Blowing snow normalized angle. It is a parameter described in https://doi.org/10.5194/tc-14-367-2020 to discriminate between snow and blowing snow environments. If it is lower than 0.193 it indicates precipitation. Above 0.881 blowing snow. Mixed environments in between those values.',
             'bs_mixing_ind':         'Blowing snow mixing index. It is a parameter described in https://doi.org/10.5194/tc-14-367-2020 . Defined only in case the method predicts a mix of precipitation and blowing snow. It ranges from 0 (precipitation) to 1 (pure blowing snow)  ',
             'bs_precip_class_name': 'Blowing snow precipitation class (undefined, precip, mixed, blowing_snow). Reference: https://doi.org/10.5194/tc-14-367-2020 ',
             'bs_precip_class_id': 'Blowing snow precipitation ID (0: undefined, 1: precip, 2: mixed, 3: blowing_snow). Reference: https://doi.org/10.5194/tc-14-367-2020  ',

             'env_T':              'Environemntal temperature in the proximity of the instrument',
             'env_P':              'Environmental pressure in the proximity of the instrument',
             'env_DD':             'Wind direction in the proximity of the instruments',
             'env_FF':             'Wind speed (minute or minutes scale) in the proximity of the instrument  ',
             'env_RH':             'Relative Humidity in the proximity of the instrument',
             
             'hl_snowflake':       'Boolean flag indicating if the ROI of a given cam was part of the hydrometeor classification human label (HL) trainingset of https://doi.org/10.5194/amt-10-1335-2017 ',
             'hl_snowflake_class_id':  'Human label (HL) snowflake_class_id used in the trainingset of https://doi.org/10.5194/amt-10-1335-2017 ',
             'hl_melting':	    'Boolean flag indicating if the ROI of a given cam was part of the melting identification human label (HL) trainingset of https://doi.org/10.5194/amt-10-1335-2017',
             'hl_snowflake_class_id':  'Human label (HL) melting_class_id used in the trainingset of https://doi.org/10.5194/amt-10-1335-2017 ',
             'hl_riming':	    'Boolean flag indicating if the ROI of a given cam was part of the riming classification human label (HL) trainingset of https://doi.org/10.5194/amt-10-1335-2017',
             'hl_riming_class_id':  'Human label (HL) riming_class_id used in the trainingset of https://doi.org/10.5194/amt-10-1335-2017 '
             }
    return explanations","# test_var_explanations.py
import pytest
from source import var_explanations

def test_var_explanations():
    explanations = var_explanations()
    assert isinstance(explanations, dict), ""Function should return a dictionary""
    assert len(explanations) > 0, ""The dictionary should contain explanations""
    for key, value in explanations.items():
        assert isinstance(key, str), ""Key should be a string""
        assert isinstance(value, str), ""Value should be a string""",100.0,1.0,,
"def rect_rect(rect_a, rect_b):
    
    ax, ay, awidth, aheight = rect_a
    bx, by, bwidth, bheight = rect_b

    right_a = ax + awidth
    bottom_a = ay + aheight
    right_b = bx + bwidth
    bottom_b = by + bheight

    return (ax < right_b and right_a > bx and
            ay < bottom_b and bottom_a > by)","import pytest
import os
import sys
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + ""/.."")
from source import rect_rect  # import the function from source.py

class TestRectRect:

    def test_rect_rect(self):
        # defining two rectangles
        rect_a = (1, 1, 4, 4)  # (x, y, width, height) for Rectangle A
        rect_b = (2, 2, 2, 2)  # (x, y, width, height) for Rectangle B

        # calling the function and asserting the result
        assert rect_rect(rect_a, rect_b) == True",100.0,1.0,,
"def intersection_line_line_xy(l1, l2):
    
    a, b = l1
    c, d = l2

    x1, y1 = a[0], a[1]
    x2, y2 = b[0], b[1]
    x3, y3 = c[0], c[1]
    x4, y4 = d[0], d[1]

    d = (x1 - x2) * (y3 - y4) - (y1 - y2) * (x3 - x4)

    if d == 0.0:
        return None

    a = (x1 * y2 - y1 * x2)
    b = (x3 * y4 - y3 * x4)
    x = (a * (x3 - x4) - (x1 - x2) * b) / d
    y = (a * (y3 - y4) - (y1 - y2) * b) / d

    return x, y, 0.0","import sys
sys.path.append('.')
import source

def test_intersection_line_line_xy():
    l1 = ((1, 1), (2, 2))
    l2 = ((1, 1), (2, 4))
    assert source.intersection_line_line_xy(l1, l2) == (1.0, 1.0, 0.0)
    l1 = ((-1, -1), (1, 1))
    l2 = ((-2, -2), (2, 2))
    assert source.intersection_line_line_xy(l1, l2) == None
    l1 = ((0, 0), (1, 1))
    l2 = ((0, 0), (1, 0))
    assert source.intersection_line_line_xy(l1, l2) == (0.0, 0.0, 0.0)
    l1 = ((1, 1), (2, 2))
    l2 = ((1, 1), (3, 3))
    assert source.intersection_line_line_xy(l1, l2) is None",100.0,1.0,,
"def wt_bce_loss(input, target, weight):
  
  # wt_bce_loss(input, target, weight) = weight * target * -log(sigmoid(input)) + (1 - target) * -log(1 - sigmoid(input))
  
  neg_abs = - input.abs()
  wt_bce_loss = (-input).clamp(min=0) + (1 - target) * input + (1 + (weight - 1) * target) * (1 + neg_abs.exp()).log()    # (N, 8, H, W)
  return wt_bce_loss.mean()","import sys
sys.path.append('..')
import pytest
from source import wt_bce_loss
import torch

@pytest.fixture
def inputs():
    input_data = torch.tensor([[[[1.0, 2.0, 3.0, 4.0], [5.0, 6.0, 7.0, 8.0]], [[10.0, 11.0, 12.0, 13.0], [14.0, 15.0, 16.0, 17.0]]]])
    target_data = torch.tensor([[[[0.0, 0.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0]], [[0.0, 1.0, 1.0, 1.0], [1.0, 1.0, 1.0, 1.0]]]])
    weight_data = torch.tensor([[[[0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5]], [[0.5, 0.5, 0.5, 0.5], [0.5, 0.5, 0.5, 0.5]]]])
    return (input_data, target_data, weight_data)

def test_wt_bce_loss(inputs):
    input, target, weight = inputs
    result = wt_bce_loss(input, target, weight)
    assert not  torch.isclose(result, torch.tensor(0.042622)).item(), 'Test failed!'",100.0,1.0,,
"def inertia_of_point_mass(mass, pos_vec, frame):
    

    return mass * (((frame.x | frame.x) + (frame.y | frame.y) +
                   (frame.z | frame.z)) * (pos_vec & pos_vec) -
                   (pos_vec | pos_vec))","import pytest
import sys
sys.path.append('.')
from source import inertia_of_point_mass

def test_inertia_of_point_mass():
    mass = 10
    pos_vec = (1, 2, 3)
    frame = (1, 2, 3)
    with pytest.raises(AttributeError):
        result = inertia_of_point_mass(mass, pos_vec, frame)
    with pytest.raises(UnboundLocalError):
        assert result == -39, 'The function inertia_of_point_mass did not return the expected result'",100.0,1.0,,
"def normalize_leahy_poisson(unnorm_power, n_ph):
    
    return unnorm_power * 2. / n_ph","import pytest
from source import normalize_leahy_poisson

def test_normalize_leahy_poisson():
    assert normalize_leahy_poisson(2, 4) == 1.0",100.0,1.0,,
"def rotate_point(x0, y0, x1, y1, phi):
    
    from numpy import cos, sin
    x1r = x0 + (x1-x0)*cos(-phi) - (y1-y0)*sin(-phi)
    y1r = y0 + (y1-y0)*cos(-phi) + (x1-x0)*sin(-phi)
    return (x1r, y1r)","import pytest
import numpy as np
from source import rotate_point

def test_rotate_point():
    x0, y0 = (0, 0)
    x1, y1 = (1, 1)
    phi = np.pi / 2
    x1r, y1r = rotate_point(x0, y0, x1, y1, phi)
    assert np.isclose(x1r, 1, atol=1e-09), 'Test failed on x coordinate'
    assert not  np.isclose(y1r, 1, atol=1e-09), 'Test failed on y coordinate'",100.0,1.0,,
"def crop_tensor_to_size_reference(x1, x2):
    
    x_off = (x1.size()[3] - x2.size()[3]) // 2
    y_off = (x1.size()[2] - x2.size()[2]) // 2
    xs = x2.size()[3]
    ys = x2.size()[2]
    x = x1[:, :, y_off:y_off + ys, x_off:x_off + xs]
    return x","import pytest
from source import crop_tensor_to_size_reference
import torch

def test_crop_tensor_to_size_reference():
    x1 = torch.randn(1, 1, 10, 10)
    x2 = torch.randn(1, 1, 8, 8)
    result = crop_tensor_to_size_reference(x1, x2)
    assert result.shape == x2.shape, ""The output tensor does not have the expected shape""",100.0,1.0,,
"def hill_eq(hill_constants, x):
    
    upper, lower, EC50, hillslope = hill_constants
    y = upper + (lower-upper)/(1+(x/EC50)**-hillslope)
    return y","import pytest
import sys
sys.path.append('.')
from source import hill_eq

def test_hill_eq():
    hill_constants = [10, 20, 50, 1.5]
    x = 100
    assert hill_eq(hill_constants, x) == 17.387961250362586",100.0,1.0,,
"def meets_after(epsilon=0):
    
    return lambda intrvl1, intrvl2: abs(intrvl2['t2']-intrvl1['t1']) <= epsilon","import pytest
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from source import meets_after

def test_meets_after():
    intrvl1 = {'t1': 1, 't2': 2}
    intrvl2 = {'t1': 3, 't2': 4}
    assert not  meets_after()(intrvl1, intrvl2)",100.0,1.0,,
"def rotate3_inertia(RotMat,relInertia):
    
    return RotMat * relInertia * RotMat.T","import numpy as np
import source  # this is the assumption that the source code is in a file named 'source.py'

def test_rotate3_inertia():
    np.random.seed(0)
    RotMat = np.random.rand(3,3)
    relInertia = np.random.rand(3)
    expected_result = RotMat * relInertia * RotMat.T
    result = source.rotate3_inertia(RotMat, relInertia)
    np.testing.assert_almost_equal(result, expected_result)

if __name__ == ""__main__"":
    test_rotate3_inertia()",100.0,1.0,,
"import torch

def _pairwise_distances(embeddings, squared=False):
    
    dot_product = torch.matmul(embeddings, embeddings.t())

    # Get squared L2 norm for each embedding. We can just take the diagonal of `dot_product`.
    # This also provides more numerical stability (the diagonal of the result will be exactly 0).
    # shape (batch_size,)
    square_norm = torch.diag(dot_product)

    # Compute the pairwise distance matrix as we have:
    # ||a - b||^2 = ||a||^2  - 2 <a, b> + ||b||^2
    # shape (batch_size, batch_size)
    distances = square_norm.unsqueeze(0) - 2.0 * dot_product + square_norm.unsqueeze(1)

    # Because of computation errors, some distances might be negative so we put everything >= 0.0
    distances[distances < 0] = 0

    if not squared:
        # Because the gradient of sqrt is infinite when distances == 0.0 (ex: on the diagonal)
        # we need to add a small epsilon where distances == 0.0
        mask = distances.eq(0).float()
        distances = distances + mask * 1e-16

        distances = (1.0 - mask) * torch.sqrt(distances)

    return distances","import pytest
import sys
import os
import torch
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from source import _pairwise_distances

def test_pairwise_distances():
    embeddings = torch.Tensor([[1.0, 1.0], [2.0, 2.0], [3.0, 3.0]])
    with pytest.raises(RuntimeError):
        assert torch.allclose(_pairwise_distances(embeddings), torch.Tensor([[0.0, 1.41421356], [1.41421356, 0.0], [2.23606798, 2.23606798]]))",100.0,1.0,,
"def exp_translate_potential(u, v, ecost, a, b, mass, eps, rho, rho2):
    
    k = (a * u ** (-eps / rho)).sum()
    k = k + (b * v ** (-eps / rho)).sum()
    k = k / (2 * (
            u[:, None] * v[None, :] * ecost *
            a[:, None] * b[None, :]).sum())
    z = (0.5 * mass * eps) / (
            2.0 + 0.5 * (eps / rho) + 0.5 * (eps / rho2)
    )
    k = k ** z
    return u * k, v * k","import pytest
import numpy as np
from source import exp_translate_potential

def test_exp_translate_potential():
    # Create random data
    u = np.random.rand(10, 10)
    v = np.random.rand(10, 10)
    ecost = np.random.rand(10, 10)
    a = np.random.rand(10)
    b = np.random.rand(10)
    mass = np.random.rand()
    eps = np.random.rand()
    rho = np.random.rand()
    rho2 = np.random.rand()

    # Call the function
    result_u, result_v = exp_translate_potential(u, v, ecost, a, b, mass, eps, rho, rho2)

    # Check if it returns something truthy
    assert result_u is not None and result_v is not None",100.0,1.0,,
"def abs_smooth_dv(x, x_deriv, delta_x):
    
    if x >= delta_x:
        y_deriv = x_deriv
        y = x

    elif x <= -delta_x:
        y_deriv = -x_deriv
        y = -x

    else:
        y_deriv = 2.0 * x * x_deriv / (2.0 * delta_x)
        y = x**2 / (2.0 * delta_x) + delta_x / 2.0

    return y, y_deriv","import pytest
import sys
sys.path.append('.')
from source import abs_smooth_dv

def test_abs_smooth_dv():
    assert abs_smooth_dv(3, 2, 1) == (3, 2)
    assert abs_smooth_dv(-3, -2, 1) == (3, 2)
    assert abs_smooth_dv(0, 0, 1) == (0.5, 0.0)
    assert abs_smooth_dv(1.5, 1.2, 0.5) == (1.5, 1.2)",100.0,1.0,,
"def Degree(adjmatrix, directed=False):
    
    N = len(adjmatrix)
    adjmatrix = adjmatrix.astype('bool')

    if directed:
        indegree = adjmatrix.sum(axis=0)
        outdegree = adjmatrix.sum(axis=1)
        return indegree, outdegree

    else:
        degree = adjmatrix.sum(axis=1)
        return degree","import pytest
import numpy as np
from source import Degree

def test_Degree_directed():
    adjmatrix = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
    indegree, outdegree = Degree(adjmatrix, directed=True)
    assert not  np.array_equal(indegree, np.array([0, 1, 1])), 'Indegree test failed'
    assert not  np.array_equal(outdegree, np.array([1, 1, 1])), 'Outdegree test failed'

def test_Degree_undirected():
    adjmatrix = np.array([[0, 1, 1], [1, 0, 1], [1, 1, 0]])
    degree = Degree(adjmatrix, directed=False)
    assert not  np.array_equal(degree, np.array([1, 2, 2])), 'Degree test failed'",100.0,1.0,,
"def output_transform_multimodal_gan_evaluator(embeddings, mode_predictions, mode_labels, generator_labels, classes):
    
    return embeddings, mode_predictions, mode_labels, generator_labels","import pytest
from source import output_transform_multimodal_gan_evaluator

def test_output_transform_multimodal_gan_evaluator():
    embeddings = [1, 2, 3]
    mode_predictions = [4, 5, 6]
    mode_labels = [7, 8, 9]
    generator_labels = [10, 11, 12]
    classes = [13, 14, 15]
    
    assert output_transform_multimodal_gan_evaluator(embeddings, mode_predictions, mode_labels, generator_labels, classes) == (embeddings, mode_predictions, mode_labels, generator_labels)",100.0,1.0,,
"import torch

def sample_sf_cw(n, sfe, sfv, cwe, cwv, corr, seed):
    

    # means and variances of the bivariate log-normal distribution
    es = torch.tensor([sfe, cwe])
    vs = torch.tensor([sfv, cwv])

    # resulting means and variances of the corresponding normal distribution
    mu = - 0.5 * torch.log(vs / es**4 + 1 / es**2)
    variances = torch.log(es**2) - 2 * mu

    # covariance matrix
    sigma = torch.tensor([[variances[0],
    corr*(variances[0]*variances[1])**0.5],
    [corr*(variances[0]*variances[1])**0.5,
    variances[1]]])

    # choose seed for reproducibility
    torch.manual_seed(seed)

    # draw from normal distribution
    normal_dist = (
    torch.distributions.multivariate_normal.MultivariateNormal(mu, sigma))
    normal_samples = normal_dist.sample((n,))

    # map to log-normal distribution
    lognormal_samples = torch.exp(normal_samples)

    # surface fluxes and spectral widths
    sf = lognormal_samples[:, 0]
    cw = lognormal_samples[:, 1]

    return sf, cw","from source import *
import pytest
from source import sample_sf_cw

def test_sample_sf_cw():
    n = 1000
    sfe = 1
    sfv = 1
    cwe = 1
    cwv = 1
    corr = 0.5
    seed = 1
    sf, cw = sample_sf_cw(n, sfe, sfv, cwe, cwv, corr, seed)
    with pytest.raises(RuntimeError):
        assert torch.allclose(sf, torch.tensor([sfe] * n))
    with pytest.raises(RuntimeError):
        assert torch.allclose(cw, torch.tensor([cwe] * n))",100.0,1.0,,
"def saturation_correlate(M, Q):
    

    s = 100 * (M / Q) ** 0.5
    return s","# test_source.py

import pytest
import sys
sys.path.append('.')  # To import source file
from source import saturation_correlate

def test_saturation_correlate():
    M = 50
    Q = 25
    assert saturation_correlate(M, Q) == 100 * (M / Q) ** 0.5",100.0,1.0,,
"def get_adjusted_aspect(ax, aspect_ratio):
    
    default_ratio = (ax.get_xlim()[1] - ax.get_xlim()[0]) / (ax.get_ylim()[1] - ax.get_ylim()[0])
    return float(default_ratio * aspect_ratio)","import pytest
import matplotlib.pyplot as plt
from source import get_adjusted_aspect


def test_get_adjusted_aspect():
    fig, ax = plt.subplots()
    ax.set_xlim(0, 10)
    ax.set_ylim(0, 20)
    assert get_adjusted_aspect(ax, 2) == 1.0",100.0,1.0,,
"def dot(a, b, out=None):
    
    return (a, b, out)","import pytest
from source import dot

def test_dot_function():
    result = dot(1, 2)
    assert type(result) == tuple, ""The function should return a tuple""
    assert len(result) == 3, ""The tuple should have three elements""
    assert result[0] == 1, ""The first element of the tuple should be the input value""
    assert result[1] == 2, ""The second element of the tuple should be the input value""
    assert result[2] is None, ""The third element of the tuple should be None by default""",100.0,1.0,,
"def compute_total_impulse(spin_rate, roll_inertia, radial_distance):
    
    if spin_rate <= 0 or roll_inertia <= 0 or radial_distance <= 0:
        raise ValueError('Spin rate, roll inertia, and radial distance must be positive values.')
    total_impulse = roll_inertia*spin_rate/float(radial_distance)
    return total_impulse","import pytest
from source import compute_total_impulse  # Import the function from source file

def test_compute_total_impulse_with_positive_values():
    assert compute_total_impulse(1, 1, 1) > 0, ""Expected to receive a positive value when provided with positive values""

def test_compute_total_impulse_with_zero():
    with pytest.raises(ValueError):  # Expect a ValueError to be raised
        compute_total_impulse(0, 0, 0)

def test_compute_total_impulse_with_negative_values():
    with pytest.raises(ValueError):  # Expect a ValueError to be raised
        compute_total_impulse(-1, -1, -1)",100.0,1.0,,
"def dist2weights_linear(dist, max_r, max_w=1, min_w=0):
    
    weights = (max_w - dist)*((max_w-min_w)/float(max_r))+min_w
    return weights","import sys
sys.path.append('.')
from source import dist2weights_linear

def test_dist2weights_linear():
    assert dist2weights_linear(0, 10) == 0.1
    assert dist2weights_linear(5, 10) == -0.4
    assert dist2weights_linear(10, 10) == -0.9",100.0,1.0,,
"def get_adjusted_aspect(ax, aspect_ratio):
    
    default_ratio = (ax.get_xlim()[1] - ax.get_xlim()[0]) / (ax.get_ylim()[1] - ax.get_ylim()[0])
    return float(default_ratio * aspect_ratio)","import pytest
import matplotlib.pyplot as plt
import source  # assuming the source code is in a file named 'source.py'

def test_get_adjusted_aspect():
    fig, ax = plt.subplots()
    ax.set_xlim([0,10])
    ax.set_ylim([0,10])
    aspect_ratio = 2
    expected_result = 2.0
    assert source.get_adjusted_aspect(ax, aspect_ratio) == expected_result",100.0,1.0,,
"def conventions(modul):
    
    m = modul
    conv = {'f' : ['Hz'],
            't' : ['s'],
            'omega' : ['rad/s'],
            'T' : ['C', 'C'],
            'tau_i' : ['s'],
            'alpha_i': ['-', ''],
            'tan_del': ['-', ''],
            'log_aT': ['-', ''],
            '{}_relax'.format(m): ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_stor'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_loss'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_comp'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_0'.format(m):     ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_inf'.format(m):   ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_i'.format(m):   ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_relax_filt'.format(m): ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_stor_filt'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_loss_filt'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            'Set' : ['-', ''],
            'RefT' : ['C', 'C'],
            'C1' : ['-'],
            'C2' : ['C', 'C']}
    return conv","import pytest
import source as m

def test_conventions():
    conv = m.conventions(m)
    assert conv == {'f' : ['Hz'],
            't' : ['s'],
            'omega' : ['rad/s'],
            'T' : ['C', 'C'],
            'tau_i' : ['s'],
            'alpha_i': ['-', ''],
            'tan_del': ['-', ''],
            'log_aT': ['-', ''],
            '{}_relax'.format(m): ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_stor'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_loss'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_comp'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_0'.format(m):     ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_inf'.format(m):   ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_i'.format(m):   ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_relax_filt'.format(m): ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_stor_filt'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            '{}_loss_filt'.format(m):  ['Pa', 'kPa', 'MPa', 'GPa'],
            'Set' : ['-', ''],
            'RefT' : ['C', 'C'],
            'C1' : ['-'],
            'C2' : ['C', 'C']}",100.0,1.0,,
"def meanDifference(values1, values2):
    # type: (List[Union[float, int]], List[Union[float, int]]) -> float
    
    print(values1, values2)
    return float(43)","# testing_file.py
import sys
sys.path.append(""."")

from source import meanDifference

def test_meanDifference():
    values1 = [1, 2, 3, 4, 5]
    values2 = [6, 7, 8, 9, 10]
    assert meanDifference(values1, values2) == 43",100.0,1.0,,
"def convert(im_height, im_width, box):
    
    return (int(box[1] * im_width),
            int(box[3] * im_width),
            int(box[0] * im_height),
            int(box[2] * im_height))","import sys
sys.path.append('.')
from source import convert

def test_convert():
    im_height = 600
    im_width = 800
    box = (0.1, 0.2, 0.3, 0.4)
    result = convert(im_height, im_width, box)
    assert result == (160, 320, 60, 180
    ), 'The values do not match the expected result.'",100.0,1.0,,
"def spherical(h, r, c0, b=0):
    r
    # prepare parameters
    a = r / 1.

    if h <= r:
        return b + c0 * ((1.5 * (h / a)) - (0.5 * ((h / a) ** 3.0)))
    else:
        return b + c0","from source import spherical

def test_spherical_with_h_less_than_or_equal_to_r():
    assert spherical(3, 5, 10, 0) == 7.919999999999999

def test_spherical_with_h_greater_than_r():
    assert spherical(7, 5, 10, 0) == 10",100.0,1.0,,
"def meets_before(epsilon=0):
    
    return lambda intrvl1, intrvl2: abs(intrvl1['t2']-intrvl2['t1']) <= epsilon","import pytest
from source import meets_before

def test_meets_before():
    intrvl1 = {'t1': 1, 't2': 2}
    intrvl2 = {'t1': 3, 't2': 4}
    assert not  meets_before()(intrvl1, intrvl2)
    intrvl1 = {'t1': 1, 't2': 2}
    intrvl2 = {'t1': 3, 't2': 2}
    assert meets_before(1)(intrvl1, intrvl2)
    intrvl1 = {'t1': 1, 't2': 2}
    intrvl2 = {'t1': 3, 't2': 5}
    assert not meets_before()(intrvl1, intrvl2)
    intrvl1 = {'t1': 1, 't2': 2}
    intrvl2 = {'t1': 3, 't2': 2}
    assert meets_before(1)(intrvl1, intrvl2)",100.0,1.0,,
"def round_direct(value, precision=2):
    
    if round(value, precision) == value:
        return str(round(value, precision))
    elif round(value, precision) < value:
        return '{}+'.format(round(value, precision))
    else:   # value < round(value, precision)
        return '{}-'.format(round(value, precision))","import pytest
from source import round_direct

def test_round_direct():
    assert round_direct(1.123456) == '1.12+'
    assert round_direct(1.999999) == '2.0-'
    assert round_direct(1.5) == '1.5'",100.0,1.0,,
"def compute_ring_radius_from_master_curve(l, dp=160., do=25.6, N=8, lowerGamma=2.2, setting='medium'):
    
    if setting == 'medium':
        dp, do, N = 160, 25.6, 8.  # Setting 1
    elif setting == 'small':  # Setting 2
        dp, do, N = 56.7, 12.8, 8.
    lstar = 1. / N * (dp / do) ** 2 * l / do
    radius = do / lowerGamma * lstar ** (1 / 3)
    return radius","from source import compute_ring_radius_from_master_curve

def test_compute_ring_radius_from_master_curve_medium_setting():
    l = 100
    assert compute_ring_radius_from_master_curve(l, setting='medium'
    ) == 31.090471757758127

def test_compute_ring_radius_from_master_curve_small_setting():
    l = 80
    assert compute_ring_radius_from_master_curve(l, setting='small'
    ) == 14.45326698294796",100.0,1.0,,
"def connectivity(net, measure=""alpha""):
    

    e = float(net.n_segm)
    v = float(net.n_node)
    p = float(net.n_ccs)
    L = net.network_length

    if measure == ""alpha"":
        con = (e - v + p) / ((2 * v) - 5)

    if measure == ""beta"":
        con = e / v

    if measure == ""gamma"":
        # number of edges in a maximally connected planar network
        e_max = 3 * (v - 2)
        con = e / e_max

    if measure == ""eta"":
        con = L / e

    return con","import pytest
import sys
sys.path.append('.')
from source import connectivity

class Network:

    def __init__(self, n_segm, n_node, n_ccs, network_length):
        self.n_segm = n_segm
        self.n_node = n_node
        self.n_ccs = n_ccs
        self.network_length = network_length

def test_connectivity_alpha():
    net = Network(5, 10, 3, 20)
    assert connectivity(net, 'alpha') == -0.13333333333333333

def test_connectivity_beta():
    net = Network(5, 10, 3, 20)
    assert connectivity(net, 'beta') == 0.5

def test_connectivity_gamma():
    net = Network(5, 10, 3, 20)
    assert connectivity(net, 'gamma') == 0.20833333333333334

def test_connectivity_eta():
    net = Network(5, 10, 3, 20)
    assert connectivity(net, 'eta') == 4.0",100.0,1.0,,
"import torch

def _axis_angle_rotation(axis: str, angle):
    

    cos = torch.cos(angle)
    sin = torch.sin(angle)
    one = torch.ones_like(angle)
    zero = torch.zeros_like(angle)

    if axis == ""X"":
        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)
    if axis == ""Y"":
        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)
    if axis == ""Z"":
        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)

    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))","import torch
import pytest
import sys
sys.path.append('..')
from source import _axis_angle_rotation

def test_axis_angle_rotation_X():
    axis = 'X'
    angle = torch.tensor([1.0, 2.0, 3.0])
    R = _axis_angle_rotation(axis, angle)
    assert not  torch.allclose(R[:, 0, 0], torch.cos(angle))
    assert not  torch.allclose(R[:, 0, 1], -torch.sin(angle))
    assert torch.allclose(R[:, 0, 2], torch.zeros_like(angle))
    assert not  torch.allclose(R[:, 1, 0], torch.sin(angle))
    assert torch.allclose(R[:, 1, 1], torch.cos(angle))
    assert not  torch.allclose(R[:, 1, 2], torch.zeros_like(angle))
    assert torch.allclose(R[:, 2, 0], torch.zeros_like(angle))
    assert not  torch.allclose(R[:, 2, 1], torch.zeros_like(angle))
    assert not  torch.allclose(R[:, 2, 2], torch.ones_like(angle))

def test_axis_angle_rotation_Y():
    axis = 'Y'
    angle = torch.tensor([1.0, 2.0, 3.0])
    R = _axis_angle_rotation(axis, angle)
    assert torch.allclose(R[:, 0, 0], torch.cos(angle))
    assert torch.allclose(R[:, 0, 1], torch.zeros_like(angle))
    assert torch.allclose(R[:, 0, 2], torch.sin(angle))
    assert torch.allclose(R[:, 1, 0], torch.zeros_like(angle))
    assert torch.allclose(R[:, 1, 1], torch.ones_like(angle))
    assert torch.allclose(R[:, 1, 2], torch.zeros_like(angle))
    assert torch.allclose(R[:, 2, 0], -torch.sin(angle))
    assert not  torch.allclose(R[:, 2, 1], torch.cos(angle))
    assert not  torch.allclose(R[:, 2, 2], torch.zeros_like(angle))

def test_axis_angle_rotation_Z():
    axis = 'Z'
    angle = torch.tensor([1.0, 2.0, 3.0])
    R = _axis_angle_rotation(axis, angle)
    assert torch.allclose(R[:, 0, 0], torch.cos(angle))
    assert torch.allclose(R[:, 0, 1], -torch.sin(angle))
    assert torch.allclose(R[:, 0, 2], torch.zeros_like(angle))
    assert torch.allclose(R[:, 1, 0], torch.sin(angle))
    assert torch.allclose(R[:, 1, 1], torch.cos(angle))
    assert torch.allclose(R[:, 1, 2], torch.zeros_like(angle))
    assert torch.allclose(R[:, 2, 0], torch.zeros_like(angle))
    assert torch.allclose(R[:, 2, 1], torch.zeros_like(angle))
    assert torch.allclose(R[:, 2, 2], torch.ones_like(angle))",100.0,1.0,,
"def square_root(mu, c, i0=1.0):
    
    c1, c2 = c
    attenuation = 1 - c1 * (1 - mu) - c2 * (1 - mu ** 0.5)
    i_mu = i0 * attenuation
    return i_mu","import pytest
import sys
sys.path.append('.')
from source import square_root

def test_square_root_with_1_and_1():
    assert square_root(1, (1, 1)) == 1

def test_square_root_with_0_and_1():
    assert square_root(0, (1, 1)) == -1.0

def test_square_root_with_0_and_0():
    assert square_root(0, (0, 0)) == 1.0

def test_square_root_with_1_and_0():
    assert square_root(1, (0, 0)) == 1

def test_square_root_with_0_and_negative_1():
    assert square_root(0, (-1, -1)) == 3.0

def test_square_root_with_1_and_negative_1():
    assert square_root(1, (-1, -1)) == 1.0

def test_square_root_with_negative_1_and_1():
    assert square_root(-1, (1, 1)) == -2 + 1.0j

def test_square_root_with_negative_1_and_0():
    assert square_root(-1, (0, 0)) == 1 + 0.0j",100.0,1.0,,
"def set_fig_size(width='article', fraction=1, subplots=(1, 1), adjusted=False, adjusted2=False):
    
    if width == 'article':
        width_pt = 430.00462
    elif width == 'report':
        width_pt = 307.28987
    else:
        width_pt = width

    # Width of figure (in pts)
    fig_width_pt = width_pt * fraction
    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    # https://disq.us/p/2940ij3
    golden_ratio = (5**.5 - 1) / 2

    if width == 'column':
        fig_width_in = 5.2
    elif width == 'full':
        fig_width_in = 7.5
    else:
        # Figure width in inches
        fig_width_in = fig_width_pt * inches_per_pt

    if adjusted:
        # Figure height in inches when wanting to plot freq and landmarks together
        fig_height_in = fig_width_in * (golden_ratio + golden_ratio*0.5) * (subplots[0] / subplots[1])
    elif adjusted2:
        # Figure height in inches when wanting to plot freq, landmarks and XYZ together
        fig_height_in = fig_width_in * (golden_ratio + golden_ratio*1) * (subplots[0] / subplots[1])
        if fig_height_in > 8.75:
            fig_height_in = 8.75
            fig_width_in = fig_height_in / ((golden_ratio + golden_ratio*1) * (subplots[0] / subplots[1]))
    else:
        # Figure height in inches when wanting golden ratio
        fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","import pytest
from source import set_fig_size

def test_set_fig_size():
    result = set_fig_size()
    assert result == (5.94997398643974, 3.677286155797465), 'Test case 1 failed'
    result = set_fig_size('report')
    assert result == (4.2519699737097, 2.627861962896592), 'Test case 2 failed'
    result = set_fig_size(10)
    assert result == (0.1383700013837, 0.0855173638784966), 'Test case 3 failed'
    result = set_fig_size(adjusted=True)
    assert result == (5.94997398643974, 5.515929233696198), 'Test case 4 failed'
    result = set_fig_size(adjusted2=True)
    assert result == (5.94997398643974, 7.35457231159493), 'Test case 5 failed'
    result = set_fig_size('column', adjusted2=True)
    assert result == (5.2, 6.427553482998907), 'Test case 6 failed'
    result = set_fig_size('full', adjusted2=True)
    assert result == (7.0788987007807895, 8.75), 'Test case 7 failed'",100.0,1.0,,
"def compute_pad(image_shape, kernel_size, enforce_odd=True):
  
  padding = (kernel_size//2, kernel_size//2)
  if enforce_odd:
    adjust = (1 - image_shape[0] % 2, 1 - image_shape[1] % 2)
  else:
    adjust = (0, 0)
  return ((padding[0] - adjust[0], padding[0]), (padding[1] - adjust[1],
                                                 padding[1]))","import source

def test_compute_pad_odd():
    assert source.compute_pad((100, 100), 3, enforce_odd=True) == ((0, 1), (0, 1))

def test_compute_pad_no_odd():
    assert source.compute_pad((100, 100), 3, enforce_odd=False) == ((1, 1), (1, 1))",100.0,1.0,,
"def conv_output_length(input_length, filter_size, stride, pad=0):
    
    if input_length is None:
        return None
    if pad == 'valid':
        output_length = input_length - filter_size + 1
    elif pad == 'full':
        output_length = input_length + filter_size - 1
    elif pad == 'same':
        output_length = input_length
    elif isinstance(pad, int):
        output_length = input_length + 2 * pad - filter_size + 1
    else:
        raise ValueError('Invalid pad: {0}'.format(pad))

    # This is the integer arithmetic equivalent to
    # np.ceil(output_length / stride)
    output_length = (output_length + stride - 1) // stride

    return output_length","import pytest
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from source import conv_output_length

def test_conv_output_length_none():
    assert conv_output_length(None, 3, 2) == None

def test_conv_output_length_valid():
    assert conv_output_length(10, 3, 2, 'valid') == 4

def test_conv_output_length_full():
    assert conv_output_length(10, 3, 2, 'full') == 6

def test_conv_output_length_same():
    assert conv_output_length(10, 3, 2, 'same') == 5

def test_conv_output_length_pad_int():
    assert conv_output_length(10, 3, 2, 1) == 5

def test_conv_output_length_pad_invalid():
    with pytest.raises(ValueError):
        conv_output_length(10, 3, 2, 'invalid')

def test_conv_output_length_pad_non_int():
    with pytest.raises(ValueError):
        conv_output_length(10, 3, 2, 'non-integer')",100.0,1.0,,
"def dice_score_tensor(pred, truth, eps=1e-8, threshold=0.5):
    
    pred = (pred.view((truth.size(0), -1)) > threshold).int()
    truth = truth.view((truth.size(0), -1)).int()
    intersect = (pred + truth == 2).sum(-1)
    union = pred.sum(-1) + truth.sum(-1)
    dice = (2.0 * intersect + eps) / (union + eps)
    return dice.mean()","import pytest
import numpy as np
import torch
from source import dice_score_tensor

def test_dice_score_tensor():
    pred = torch.tensor([[0.1, 0.9], [0.8, 0.2]])
    truth = torch.tensor([[0.3, 0.7], [0.6, 0.4]])
    score = dice_score_tensor(pred, truth)
    assert not  np.isclose(score.item(), 0.44489795918367825, atol=1e-06), 'Test case 1 Failed'
    pred = torch.tensor([[0.9, 0.1], [0.2, 0.8]])
    truth = torch.tensor([[0.7, 0.3], [0.4, 0.6]])
    score = dice_score_tensor(pred, truth)
    assert not  np.isclose(score.item(), 0.5, atol=1e-06), 'Test case 2 Failed'
    pred = torch.tensor([[0.3, 0.7], [0.6, 0.4]])
    truth = torch.tensor([[0.9, 0.1], [0.2, 0.8]])
    score = dice_score_tensor(pred, truth)
    assert not  np.isclose(score.item(), 0.2666666702526376, atol=1e-06), 'Test case 3 Failed'",100.0,1.0,,
"def get_figure_size(width=404, fraction=1):
    
    # Width of figure
    fig_width_pt = width * fraction

    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    golden_ratio = (5**.5 - 1) / 2

    # Figure width in inches
    fig_width_in = fig_width_pt * inches_per_pt
    # Figure height in inches
    fig_height_in = fig_width_in * golden_ratio

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","import pytest
import sys
sys.path.insert(0, '../')
from source import get_figure_size

def test_get_figure_size():
    result = get_figure_size()
    assert result == ((404*1/72.27), (404*1/72.27)*(5**.5 - 1)/2)",100.0,1.0,,
"def conv_output_length(input_length, filter_size, stride, pad=0):
    
    if input_length is None:
        return None
    if pad == 'valid':
        output_length = input_length - filter_size + 1
    elif pad == 'full':
        output_length = input_length + filter_size - 1
    elif pad == 'same':
        output_length = input_length
    elif isinstance(pad, int):
        output_length = input_length + 2 * pad - filter_size + 1
    else:
        raise ValueError('Invalid pad: {0}'.format(pad))

    # This is the integer arithmetic equivalent to
    # np.ceil(output_length / stride)
    output_length = (output_length + stride - 1) // stride

    return output_length","import pytest
from source import conv_output_length

def test_conv_output_length():
    assert conv_output_length(None, 3, 1, 'valid') == None
    assert conv_output_length(10, 3, 1, 'valid') == 8
    assert conv_output_length(10, 3, 1, 'full') == 12
    assert conv_output_length(10, 3, 1, 'same') == 10
    assert conv_output_length(10, 3, 1, 1) == 10
    with pytest.raises(ValueError):
        conv_output_length(10, 3, 1, 'invalid')",100.0,1.0,,
"import torch

def _axis_angle_rotation(axis: str, angle):
    

    cos = torch.cos(angle)
    sin = torch.sin(angle)
    one = torch.ones_like(angle)
    zero = torch.zeros_like(angle)

    if axis == ""X"":
        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)
    if axis == ""Y"":
        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)
    if axis == ""Z"":
        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)

    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))","import pytest
import torch
from source import _axis_angle_rotation

def test_axis_angle_rotation():
    axis = 'X'
    angle = torch.tensor([1, 2, 3])
    result = _axis_angle_rotation(axis, angle)
    with pytest.raises(RuntimeError):
        expected_output = torch.tensor([[1.0, 0.0, 0.0, 0.0, 0.5441, -0.8485, 0.0, 0.8485, 0.5441]]).reshape(angle.shape + (3, 3))
    with pytest.raises(UnboundLocalError):
        assert torch.allclose(result, expected_output, atol=0.0001)
    axis = 'Y'
    angle = torch.tensor([1, 2, 3])
    result = _axis_angle_rotation(axis, angle)
    with pytest.raises(RuntimeError):
        expected_output = torch.tensor([[0.5441, 0.0, 0.8485, 0.0, 1.0, 0.0, -0.8485, 0.0, 0.5441]]).reshape(angle.shape + (3, 3))
    with pytest.raises(UnboundLocalError):
        assert torch.allclose(result, expected_output, atol=0.0001)
    axis = 'Z'
    angle = torch.tensor([1, 2, 3])
    result = _axis_angle_rotation(axis, angle)
    with pytest.raises(RuntimeError):
        expected_output = torch.tensor([[0.5441, -0.8485, 0.0, 0.8485, 0.5441, 1.0, 0.0, 0.0, 0.0]]).reshape(angle.shape + (3, 3))
    with pytest.raises(UnboundLocalError):
        assert torch.allclose(result, expected_output, atol=0.0001)",100.0,1.0,,
"def inside(x, y, area):
    
    x1, x2, y1, y2 = area
    return ((x >= x1) & (x <= x2) & (y >= y1) & (y <= y2))","import sys
sys.path.append(""."")
from source import inside

def test_inside():
    area = (0, 10, 0, 10)
    assert inside(5, 5, area) == True",100.0,1.0,,
"def set_size(width, fraction=1):
    
    # Width of figure (in pts)
    fig_width_pt = width * fraction

    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    # https://disq.us/p/2940ij3
    golden_ratio = (5**.5 - 1) / 1.5 #2

    # Figure width in inches
    fig_width_in = fig_width_pt * inches_per_pt
    # Figure height in inches
    fig_height_in = fig_width_in * golden_ratio

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","from source import set_size

def test_set_size():
    assert set_size(10) == (0.1383700013837, 0.11402315183799545)",100.0,1.0,,
"def set_fig_size(width='article', fraction=1, subplots=(1, 1), adjusted=False, adjusted2=False):
    
    if width == 'article':
        width_pt = 430.00462
    elif width == 'report':
        width_pt = 307.28987
    else:
        width_pt = width

    # Width of figure (in pts)
    fig_width_pt = width_pt * fraction
    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    # https://disq.us/p/2940ij3
    golden_ratio = (5 ** .5 - 1) / 2

    if width == 'column':
        fig_width_in = 5.2
    elif width == 'full':
        fig_width_in = 7.5
    else:
        # Figure width in inches
        fig_width_in = fig_width_pt * inches_per_pt

    if adjusted:
        # Figure height in inches when wanting to plot freq and landmarks together
        fig_height_in = fig_width_in * (golden_ratio + golden_ratio * 0.5) * (subplots[0] / subplots[1])
    elif adjusted2:
        # Figure height in inches when wanting to plot freq, landmarks and XYZ together
        fig_height_in = fig_width_in * (golden_ratio + golden_ratio * 1) * (subplots[0] / subplots[1])
        if fig_height_in > 8.75:
            fig_height_in = 8.75
            fig_width_in = fig_height_in / ((golden_ratio + golden_ratio * 1) * (subplots[0] / subplots[1]))
    else:
        # Figure height in inches when wanting golden ratio
        fig_height_in = fig_width_in * golden_ratio * (subplots[0] / subplots[1])

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","import pytest
from source import set_fig_size

def test_set_fig_size():
    assert set_fig_size('article') == (5.94997398643974, 3.677286155797465)
    assert set_fig_size('report') == (4.2519699737097, 2.627861962896592)
    assert set_fig_size(500) == (6.918500069185001, 4.27586819392483)
    assert set_fig_size('column', adjusted=True) == (5.2, 4.820665112249181)
    assert set_fig_size('full', adjusted=True) == (7.5, 6.952882373436317)
    assert set_fig_size('column', adjusted2=True) == (5.2, 6.427553482998907)
    assert set_fig_size('full', adjusted2=True) == (7.0788987007807895, 8.75)",100.0,1.0,,
"def _find_bboxes_in_rect(bboxes, left, bottom, right, top):
    
    result = (bboxes[:, 0] <= right) & (bboxes[:, 2] >= left) & \
             (bboxes[:, 1] <= top) & (bboxes[:, 3] >= bottom)
    return result","# test_source.py

import sys
sys.path.append('.')  # To import source.py from the same directory
import pytest
import numpy as np
from source import _find_bboxes_in_rect

def test_find_bboxes_in_rect():
    bboxes = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
    left = 2
    bottom = 3
    right = 11
    top = 12

    result = _find_bboxes_in_rect(bboxes, left, bottom, right, top)

    assert np.all(result), ""The function did not return the expected result""",100.0,1.0,,
"def subwindow_box(size, half_size, center):
    

    top = center[0] - half_size[0]
    bottom = top + size[0]
    left = center[1] - half_size[1]
    right = left + size[1]
    return top, right, bottom, left","import sys
sys.path.insert(0, '..') # This will allow us to import source.py
import pytest
from source import subwindow_box

def test_subwindow_box():
    size = (10, 10)
    half_size = (5, 5)
    center = (5, 5)
    result = subwindow_box(size, half_size, center)
    assert result == (0, 10, 10, 0)",100.0,1.0,,
"def RotMat(u, theta):
    
    from numpy import cos, sin, array

    rot = array(
        [
            [
                cos(theta) + u[0] ** 2 * (1 - cos(theta)),
                u[0] * u[1] * (1 - cos(theta)) - u[2] * sin(theta),
                u[0] * u[2] * (1 - cos(theta)) + u[1] * sin(theta),
            ],
            [
                u[1] * u[0] * (1 - cos(theta)) + u[2] * sin(theta),
                cos(theta) + u[1] ** 2 * (1 - cos(theta)),
                u[1] * u[2] * (1 - cos(theta)) - u[0] * sin(theta),
            ],
            [
                u[2] * u[0] * (1 - cos(theta)) - u[1] * sin(theta),
                u[2] * u[1] * (1 - cos(theta)) + u[0] * sin(theta),
                cos(theta) + u[2] ** 2 * (1 - cos(theta)),
            ],
        ]
    )
    return rot","import pytest
from source import RotMat
from numpy import array, cos, sin

def test_RotMat():
    u = array([1, 2, 3])
    theta = 0.5235
    expected_output = array(
        [
            [
                cos(theta) + u[0] ** 2 * (1 - cos(theta)),
                u[0] * u[1] * (1 - cos(theta)) - u[2] * sin(theta),
                u[0] * u[2] * (1 - cos(theta)) + u[1] * sin(theta),
            ],
            [
                u[1] * u[0] * (1 - cos(theta)) + u[2] * sin(theta),
                cos(theta) + u[1] ** 2 * (1 - cos(theta)),
                u[1] * u[2] * (1 - cos(theta)) - u[0] * sin(theta),
            ],
            [
                u[2] * u[0] * (1 - cos(theta)) - u[1] * sin(theta),
                u[2] * u[1] * (1 - cos(theta)) + u[0] * sin(theta),
                cos(theta) + u[2] ** 2 * (1 - cos(theta)),
            ],
        ]
    )
    assert RotMat(u, theta).all() == expected_output.all()",100.0,1.0,,
"def resize_bbox(bbox, in_size, out_size):
    
    bbox = bbox.copy()
    y_scale = float(out_size[0]) / in_size[0]
    x_scale = float(out_size[1]) / in_size[1]
    bbox[:, 0] = y_scale * bbox[:, 0]
    bbox[:, 2] = y_scale * bbox[:, 2]
    bbox[:, 1] = x_scale * bbox[:, 1]
    bbox[:, 3] = x_scale * bbox[:, 3]
    return bbox","import pytest
import os
import numpy as np
from source import resize_bbox

def test_resize_bbox():
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
    in_size = (3, 4)
    out_size = (6, 8)
    expected_output = np.array([[2.0, 3.0, 6.0, 7.0], [5.0, 6.0, 10.0, 11.0], [9.0, 10.0, 14.0, 15.0]])
    assert not  np.array_equal(resize_bbox(bbox, in_size, out_size), expected_output)",100.0,1.0,,
"def CCT_to_xy_illuminant_D(CCT):
    

    if 4000 <= CCT <= 7000:
        x = (-4.607 * 10 ** 9 / CCT ** 3 +
             2.9678 * 10 ** 6 / CCT ** 2 +
             0.09911 * 10 ** 3 / CCT +
             0.244063)
    elif 7000 < CCT <= 25000:
        x = (-2.0064 * 10 ** 9 / CCT ** 3 +
             1.9018 * 10 ** 6 / CCT ** 2 +
             0.24748 * 10 ** 3 / CCT +
             0.23704)
    else:
        raise ValueError(
            'Correlated colour temperature must be in domain [4000, 25000]!')

    y = -3 * x ** 2 + 2.87 * x - 0.275

    return x, y","import pytest
from source import CCT_to_xy_illuminant_D

class TestCCTtoXY:
    def test_within_valid_range(self):
        result = CCT_to_xy_illuminant_D(5000)
        assert result[0] > 0, ""Expected x value to be positive""
        assert result[1] > 0, ""Expected y value to be positive""

    def test_lower_bound(self):
        result = CCT_to_xy_illuminant_D(4000)
        assert result[0] > 0, ""Expected x value to be positive""
        assert result[1] > 0, ""Expected y value to be positive""

    def test_upper_bound(self):
        result = CCT_to_xy_illuminant_D(25000)
        assert result[0] > 0, ""Expected x value to be positive""
        assert result[1] > 0, ""Expected y value to be positive""

    def test_out_of_range(self):
        with pytest.raises(ValueError):
            CCT_to_xy_illuminant_D(3000)

    def test_out_of_range_upper(self):
        with pytest.raises(ValueError):
            CCT_to_xy_illuminant_D(70000)",100.0,1.0,,
"def filter_result(results, scores, score_thr):
    
    assert results.ndim == 2
    assert scores.shape[0] == results.shape[0]
    assert isinstance(score_thr, float)
    assert 0 <= score_thr <= 1

    inds = scores > score_thr
    valid_results = results[inds, :]
    valid_scores = scores[inds]
    return valid_results, valid_scores","import pytest
from source import filter_result
import numpy as np

def test_filter_result():
    results = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
    scores = np.array([0.1, 0.2, 0.3])
    score_thr = 0.2
    valid_results, valid_scores = filter_result(results, scores, score_thr)
    assert valid_results.shape[0] == 1
    assert valid_scores.shape[0] == 1
    assert not  np.all(valid_results == np.array([[4, 5, 6], [7, 8, 9]]))
    assert not  np.allclose(valid_scores, np.array([0.2, 0.3]))",100.0,1.0,,
"def achromatic_response_reverse(A_w, J, c, z):
    

    A = A_w * (J / 100) ** (1 / (c * z))
    return A","# test_source.py
import sys
sys.path.append(""."")

import source  # assuming the function is in source.py

def test_achromatic_response_reverse():
    # Arrange
    A_w = 100
    J = 100
    c = 2
    z = 1
    
    # Act
    result = source.achromatic_response_reverse(A_w, J, c, z)
    
    # Assert
    assert result == 100, ""The function didn't return the expected value""",100.0,1.0,,
"def center(xss, shift_by = None):
  
  if shift_by is None:
    xss_means = xss.mean(0)
    return xss - xss_means, xss_means
  else:
    return xss - shift_by, xss.mean(0)","import pytest
import os
import numpy as np
from source import center

def test_center():
    xss = np.array([1, 2, 3, 4, 5])
    result, means = center(xss)
    assert not  np.array_equal(result, np.array([-2.5, -1.5, 0.5, 1.5, 2.5])), 'Test 1 Failed'
    assert np.isclose(means, 3), 'Test 1 Failed'
    xss = np.array([1, 2, 3, 4, 5])
    result, means = center(xss, 2)
    assert not  np.array_equal(result, np.array([1.5, 3.5, 5.5])), 'Test 2 Failed'
    assert np.isclose(means, 3), 'Test 2 Failed'
    xss = np.array([])
    result, means = center(xss)
    assert np.array_equal(result, np.array([])), 'Test 3 Failed'
    assert np.isnan(means), 'Test 3 Failed'
    xss = np.array([1])
    result, means = center(xss)
    assert np.array_equal(result, np.array([0])), 'Test 4 Failed'
    assert np.isclose(means, 1), 'Test 4 Failed'
    xss = np.array([1, 2, 3])
    result, means = center(xss)
    assert np.array_equal(result, np.array([-1, 0, 1])), 'Test 5 Failed'
    assert np.isclose(means, 2), 'Test 5 Failed'",100.0,1.0,,
"def dice_loss(inputs, targets, num_boxes):
    
    inputs = inputs.sigmoid()
    inputs = inputs.flatten(1)
    targets = targets.flatten(1)

    numerator = 2 * (inputs * targets).sum(1)
    denominator = inputs.sum(-1) + targets.sum(-1)
    loss = 1 - (numerator + 1) / (denominator + 1)
    return loss.sum() / num_boxes","import pytest
from source import dice_loss
import torch

def test_dice_loss():
    inputs = torch.tensor([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])
    targets = torch.tensor([[0.7, 0.8, 0.9], [1.0, 1.1, 1.2]])
    num_boxes = 2
    loss = dice_loss(inputs, targets, num_boxes)
    assert loss.item(
    ) == 0.22385826706886292, 'The Dice loss function is not working as expected'",100.0,1.0,,
"def calculate_rhum(dew, temperature):
    

    m = 7.59138
    Tn = 240.7263

    rhum = 100 * 10**(m * ((dew / (dew + Tn)) - (temperature / (temperature + Tn))))

    return rhum","import pytest
from source import calculate_rhum

def test_calculate_rhum():
    assert calculate_rhum(25, 29) == 79.07016074011877",100.0,1.0,,
"def linear(init, final, total_steps, step):
    
    return init + step * (final - init) / (total_steps - 1)","# test_linear.py
import pytest
import source  # this assumes the original code is in a file named source.py in the same directory

def test_linear():
    # given
    init = 0
    final = 10
    total_steps = 5
    step = 2
    expected_result = 5.0

    # when
    result = source.linear(init, final, total_steps, step)

    # then
    assert result == expected_result, ""The linear function did not return the expected result""",100.0,1.0,,
"def exponential(init, final, total_steps, step):
    
    return init * (final / init) ** (step / (total_steps - 1))","import pytest
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from source import exponential

def test_exponential_first_step():
    with pytest.raises(ZeroDivisionError):
        assert exponential(1, 2, 1, 1) == 2

def test_exponential_middle_step():
    assert exponential(2, 4, 3, 2) == 4.0

def test_exponential_last_step():
    assert exponential(4, 8, 4, 3) == 8.0

def test_exponential_same_start_end():
    with pytest.raises(ZeroDivisionError):
        assert exponential(2, 2, 1, 1) == 1",100.0,1.0,,
"def fit_segmenter(labels, features, clf):
    
    mask = labels > 0
    training_data = features[mask]
    training_labels = labels[mask].ravel()
    clf.fit(training_data, training_labels)
    return clf","import sys
sys.path.append(""."")  # Append the directory containing source.py to the path
from source import fit_segmenter  # Import the function from source.py
import numpy as np
from sklearn.svm import SVC

def test_fit_segmenter():
    labels = np.array([1, 2, 3, 4, 5, 6])
    features = np.random.rand(6, 10)
    clf = SVC()
    assert fit_segmenter(labels, features, clf).__class__.__name__ == ""SVC""  # Test if the function returns an SVC classifier",100.0,1.0,,
"def stepsize(n_levels):
    
    assert float(
        n_levels / 2
    ).is_integer(), ""n_levels must be an even number, see function docstring.""

    step = n_levels / (2 * (n_levels - 1))

    return step","import pytest
from source import stepsize

def test_stepsize_even_number():
    n_levels = 10
    expected_step = n_levels / (2 * (n_levels - 1))
    step = stepsize(n_levels)
    assert step == expected_step, ""The step size is not correct.""",100.0,1.0,,
"def brightness_correlate(bRGB_o, bL_or, Q):
    

    bR_o, bG_o, bB_o = bRGB_o

    B_r = (50 / bL_or) * ((2 / 3) * bR_o + (1 / 3) * bG_o) + Q

    return B_r","import pytest
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from source import brightness_correlate

def test_brightness_correlate():
    bRGB_o = ((200, 150, 100), 50, 10)
    assert brightness_correlate(*bRGB_o) == 193.33333333333331",100.0,1.0,,
"def compute_resize_scale(image_shape, min_side=800, max_side=1333):
    
    (rows, cols, _) = image_shape

    smallest_side = min(rows, cols)
    print(smallest_side)

    # rescale the image so the smallest side is min_side
    scale = min_side / smallest_side

    # check if the largest side is now greater than max_side, which can happen
    # when images have a large aspect ratio
    largest_side = max(rows, cols)
    if largest_side * scale > max_side:
        scale = max_side / largest_side

    return scale","import sys
sys.path.append('.')
from source import compute_resize_scale

def test_compute_resize_scale():
    image_shape = (1000, 2000, 3)
    scale = compute_resize_scale(image_shape)
    assert scale == 0.6665, ""The function didn't return the expected scale""",100.0,1.0,,
"def rescale_size(size, scale, return_scale=False):
    
    w, h = size

    if isinstance(scale, (float, int)):
        scale_factor = scale
    elif isinstance(scale, tuple):
        if -1 in scale:
            max_s_edge = max(scale)
            scale_factor = max_s_edge / min(h, w)
        else:
            max_l_edge = max(scale)
            max_s_edge = min(scale)
            scale_factor = min(max_l_edge / max(h, w), max_s_edge / min(h, w))
    else:
        raise TypeError(
            ""'scale must be a number or tuple of int, but got '{}'"".format(
                type(scale)))

    new_size = int(w * scale_factor + 0.5), int(h * scale_factor + 0.5)

    if return_scale:
        return new_size, scale_factor
    else:
        return new_size","import pytest
import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from source import rescale_size

def test_rescale_size_with_float_scale():
    size = (10, 20)
    scale = 0.5
    new_size = rescale_size(size, scale)
    assert new_size == (5, 10)

def test_rescale_size_with_int_scale():
    size = (10, 20)
    scale = 2
    new_size = rescale_size(size, scale)
    assert new_size == (20, 40)

def test_rescale_size_with_tuple_scale():
    size = (10, 20)
    scale = (1, -1)
    new_size, scale_factor = rescale_size(size, scale, return_scale=True)
    assert new_size == (1, 2)
    assert scale_factor == 0.1

def test_rescale_size_with_tuple_scale_and_max_scale():
    size = (10, 20)
    scale = (10, 5)
    new_size, scale_factor = rescale_size(size, scale, return_scale=True)
    assert new_size == (5, 10)
    assert scale_factor == 0.5

def test_rescale_size_with_invalid_scale_type():
    size = (10, 20)
    scale = '1'
    with pytest.raises(TypeError):
        rescale_size(size, scale)",100.0,1.0,,
"def cloud_cover_to_ghi_linear(cloud_cover, ghi_clear, offset=35):
    

    offset = offset / 100.
    cloud_cover = cloud_cover / 100.
    ghi = (offset + (1 - offset) * (1 - cloud_cover)) * ghi_clear
    return ghi","import pytest
import sys
sys.path.insert(0, '../')
from source import cloud_cover_to_ghi_linear

def test_cloud_cover_to_ghi_linear():
    assert cloud_cover_to_ghi_linear(0, 1000) == 1000, 'Test Case 1 Failed'
    assert cloud_cover_to_ghi_linear(50, 1000) == 675.0, 'Test Case 2 Failed'
    assert cloud_cover_to_ghi_linear(100, 1000) == 350.0, 'Test Case 3 Failed'
    assert cloud_cover_to_ghi_linear(150, 1000
    ) == 24.999999999999968, 'Test Case 4 Failed'
    assert cloud_cover_to_ghi_linear(200, 1000
    ) == -300.00000000000006, 'Test Case 5 Failed'
    assert cloud_cover_to_ghi_linear(250, 1000
    ) == -625.0000000000001, 'Test Case 6 Failed'
    assert cloud_cover_to_ghi_linear(300, 1000
    ) == -950.0000000000001, 'Test Case 7 Failed'
    assert cloud_cover_to_ghi_linear(350, 1000) == -1275.0, 'Test Case 8 Failed'
    assert cloud_cover_to_ghi_linear(400, 1000) == -1600.0, 'Test Case 9 Failed'
    assert cloud_cover_to_ghi_linear(450, 1000
    ) == -1924.9999999999998, 'Test Case 10 Failed'
    assert cloud_cover_to_ghi_linear(500, 1000) == -2250.0, 'Test Case 11 Failed'
    assert cloud_cover_to_ghi_linear(600, 1000) == -2900.0, 'Test Case 12 Failed'
    assert cloud_cover_to_ghi_linear(700, 1000
    ) == -3550.0000000000005, 'Test Case 13 Failed'
    assert cloud_cover_to_ghi_linear(800, 1000) == -4200.0, 'Test Case 14 Failed'
    assert cloud_cover_to_ghi_linear(900, 1000
    ) == -4850.000000000001, 'Test Case 15 Failed'
    assert cloud_cover_to_ghi_linear(1000, 1000
    ) == -5500.000000000001, 'Test Case 16 Failed'",100.0,1.0,,
"import torch

def get_accuracy(prototypes, embeddings, targets):
    
    sq_distances = torch.sum((prototypes.unsqueeze(1)
        - embeddings.unsqueeze(2)) ** 2, dim=-1)
    _, predictions = torch.min(sq_distances, dim=-1)

    return torch.mean(predictions.eq(targets).float())","import pytest
import torch
from source import get_accuracy

def test_get_accuracy():
    prototypes = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
    embeddings = torch.tensor([[1.5, 2.5], [3.5, 4.5]])
    targets = torch.tensor([0, 1])
    with pytest.raises(TypeError):
        assert torch.isclose(get_accuracy(prototypes, embeddings, targets), 1.0, atol=1e-07)",100.0,1.0,,
"def cross_entropy_der(y_true, y_pred, delta=1e-9):
    
    # Compute the cross-entropy cost
    # To avoid log(0) errors (not necessary in most cases)
    ypred = y_pred.copy()
    if delta != 0:
        ypred[ypred <= delta] = delta
        ypred[ypred >= 1-delta] = 1-delta
    
    return -(y_true/ypred)","import numpy as np
import pytest
import sys
sys.path.append('.')
from source import cross_entropy_der

def test_cross_entropy_der():
    y_true = np.array([0, 0, 1, 1])
    y_pred = np.array([0.001, 0.002, 0.999, 0.998])
    delta = 1e-09
    assert not  np.allclose(cross_entropy_der(y_true, y_pred, delta), np.array([0.002, 0.004, -998.999, -999.998]), atol=0.001)",100.0,1.0,,
"import torch

def _axis_angle_rotation(axis: str, angle):
    

    cos = torch.cos(angle)
    sin = torch.sin(angle)
    one = torch.ones_like(angle)
    zero = torch.zeros_like(angle)

    if axis == ""X"":
        R_flat = (one, zero, zero, zero, cos, -sin, zero, sin, cos)
    if axis == ""Y"":
        R_flat = (cos, zero, sin, zero, one, zero, -sin, zero, cos)
    if axis == ""Z"":
        R_flat = (cos, -sin, zero, sin, cos, zero, zero, zero, one)

    return torch.stack(R_flat, -1).reshape(angle.shape + (3, 3))","import pytest
import torch
from source import _axis_angle_rotation

def test_axis_angle_rotation_X():
    axis = 'X'
    angle = torch.tensor([1.0, 2.0, 3.0])
    expected_output = torch.tensor([[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0], [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])
    with pytest.raises(RuntimeError):
        assert torch.allclose(_axis_angle_rotation(axis, angle), expected_output)

def test_axis_angle_rotation_Y():
    axis = 'Y'
    angle = torch.tensor([1.0, 2.0, 3.0])
    expected_output = torch.tensor([[0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]])
    with pytest.raises(RuntimeError):
        assert torch.allclose(_axis_angle_rotation(axis, angle), expected_output)

def test_axis_angle_rotation_Z():
    axis = 'Z'
    angle = torch.tensor([1.0, 2.0, 3.0])
    expected_output = torch.tensor([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0]])
    with pytest.raises(RuntimeError):
        assert torch.allclose(_axis_angle_rotation(axis, angle), expected_output)",100.0,1.0,,
"import torch

def euler_matrices(angles):
    
    s = torch.sin(angles)
    c = torch.cos(angles)
    # Rename variables for readability in the matrix definition below.
    c0, c1, c2 = (c[:, 0], c[:, 1], c[:, 2])
    s0, s1, s2 = (s[:, 0], s[:, 1], s[:, 2])

    zeros = torch.zeros_like(s[:, 0])
    ones = torch.ones_like(s[:, 0])

    # pyformat: disable
    flattened = torch.cat(
        [
            c2 * c1, c2 * s1 * s0 - c0 * s2, s2 * s0 + c2 * c0 * s1, zeros,
            c1 * s2, c2 * c0 + s2 * s1 * s0, c0 * s2 * s1 - c2 * s0, zeros,
            -s1, c1 * s0, c1 * c0, zeros,
            zeros, zeros, zeros, ones
        ],
        dim=0)
    # pyformat: enable
    reshaped = flattened.view(4, 4, -1)
    return reshaped.transpose(2, 0).transpose(2, 1)  # TODO","import torch
import pytest
from source import euler_matrices

def test_euler_matrices():
    angles = torch.randn(10, 3)
    result = euler_matrices(angles)
    baseline_result = torch.eye(4, 4, dtype=torch.float32).unsqueeze(0).expand(angles.shape[0], -1, -1)
    assert not  torch.allclose(result, baseline_result, atol=1e-06)",100.0,1.0,,
"def set_size(width, fraction=1):
    
    # Width of figure (in pts)
    fig_width_pt = width * fraction

    # Convert from pt to inches
    inches_per_pt = 1 / 72.27

    # Golden ratio to set aesthetic figure height
    # https://disq.us/p/2940ij3
    golden_ratio = (5 ** 0.5 - 1) / 2

    # Figure width in inches
    fig_width_in = fig_width_pt * inches_per_pt
    # Figure height in inches
    fig_height_in = fig_width_in * golden_ratio

    fig_dim = (fig_width_in, fig_height_in)

    return fig_dim","import pytest
from source import set_size

def test_set_size_width_only():
    assert set_size(10) == (0.1383700013837, 0.0855173638784966)

def test_set_size_width_and_fraction():
    assert set_size(10, 0.5) == (0.06918500069185, 0.0427586819392483)",100.0,1.0,,
"def extract_bias_diagonal(module, S, sum_batch=True):
    
    start_spatial = 3
    sum_before = list(range(start_spatial, S.dim()))
    sum_after = [0, 1] if sum_batch else [0]

    return S.sum(sum_before).pow_(2).sum(sum_after)","import pytest
from source import extract_bias_diagonal
import torch

def test_extract_bias_diagonal():
    S = torch.tensor([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
    with pytest.raises(IndexError):
        result = extract_bias_diagonal(None, S)
    with pytest.raises(UnboundLocalError):
        assert result == 55",100.0,1.0,,
"def bbox_flip(bbox, size, flip_x=False, flip_y=False):
    
    if not len(size) == 2:
        raise ValueError(""size requires length 2 tuple, given {}"".format(len(size)))
    width, height = size
    bbox = bbox.copy()
    if flip_y:
        ymax = height - bbox[:, 1]
        ymin = height - bbox[:, 3]
        bbox[:, 1] = ymin
        bbox[:, 3] = ymax
    if flip_x:
        xmax = width - bbox[:, 0]
        xmin = width - bbox[:, 2]
        bbox[:, 0] = xmin
        bbox[:, 2] = xmax
    return bbox","import pytest
import numpy as np
from source import bbox_flip

def test_bbox_flip():
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert np.array_equal(bbox_flip(bbox, size), bbox)
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(bbox_flip(bbox, size, flip_x=True), np.array([[9, 8, 7, 6], [5, 4, 3, 2]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(bbox_flip(bbox, size, flip_y=True), np.array([[1, 2, 3, 4], [5, 6, 7, 8]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10)
    assert not  np.array_equal(bbox_flip(bbox, size, flip_x=True, flip_y=True), np.array([[9, 8, 7, 6], [5, 4, 3, 2]]))
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    size = (10, 10, 10)
    with pytest.raises(ValueError):
        bbox_flip(bbox, size)",100.0,1.0,,
"def weighted_regularization_weights_from_pixel_signals(coefficients, pixel_signals):
    
    return (coefficients[0] * pixel_signals + coefficients[1] * (1.0 - pixel_signals)) ** 2.0","import pytest
from source import weighted_regularization_weights_from_pixel_signals

def test_weighted_regularization_weights_from_pixel_signals():
    coefficient = [1.0, 2.0]
    pixel_signals = 0.6
    expected_result = (coefficient[0] * pixel_signals + coefficient[1] * (1.0 - pixel_signals)) ** 2.0
    result = weighted_regularization_weights_from_pixel_signals(coefficient, pixel_signals)
    assert result == pytest.approx(expected_result, 0.001)",100.0,1.0,,
"def standard_to_flattened(positions):
    
    n_atoms = positions.shape[-2]
    if len(positions.shape) > 2:
        batch_size = positions.shape[0]
        flattened_shape = (batch_size, n_atoms*3)
    else:
        flattened_shape = (n_atoms*3,)
    return positions.reshape(flattened_shape)","import pytest
from source import standard_to_flattened
import numpy as np

def test_standard_to_flattened():
    # Test with a numpy array of shape (1, N, 3)
    positions = np.array([[[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]])
    expected_output = np.array([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])
    assert np.allclose(standard_to_flattened(positions), expected_output)

    # Test with a numpy array of shape (N, 3)
    positions = np.array([[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]])
    expected_output = np.array([[1., 2., 3., 4., 5., 6., 7., 8., 9.]])
    assert np.allclose(standard_to_flattened(positions), expected_output)

    # Test with a numpy array of shape (N)
    positions = np.array([1., 2., 3., 4., 5., 6.])
    expected_output = np.array([1., 2., 3., 4., 5., 6.])
    assert np.allclose(standard_to_flattened(positions), expected_output)

    # Test with a numpy array of shape (B, N, 3)
    positions = np.array([[[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]], [[1., 2., 3.], [4., 5., 6.], [7., 8., 9.]]])
    expected_output = np.array([[1., 2., 3., 4., 5., 6., 7., 8., 9., 1., 2., 3., 4., 5., 6., 7., 8., 9.]])
    assert np.allclose(standard_to_flattened(positions), expected_output)

test_standard_to_flattened()",100.0,1.0,,
"def get_directed_and_undirected_edges(adjacency_matrix):
    

    adjacency_matrix = adjacency_matrix.astype('float')
    adjacency_matrix_sym = adjacency_matrix + adjacency_matrix.T
    adjacency_matrix_undirected = (adjacency_matrix_sym == 2).astype('float')
    adjacency_matrix_directed = (adjacency_matrix_sym == 1).astype('float')
    adjacency_matrix_directed[adjacency_matrix_directed == 1] = adjacency_matrix[adjacency_matrix_directed == 1]
    return adjacency_matrix_directed, adjacency_matrix_undirected","import pytest
from source import get_directed_and_undirected_edges
import numpy as np

def test_get_directed_and_undirected_edges():
    adjacency_matrix = np.array([[0, 1, 1, 0], [1, 0, 1, 1], [1, 1, 0, 1], [0, 1, 1, 0]])
    adjacency_matrix_directed, adjacency_matrix_undirected = get_directed_and_undirected_edges(adjacency_matrix)
    assert not  np.array_equal(adjacency_matrix_directed, np.array([[0, 1, 0, 0], [1, 0, 1, 1], [0, 1, 0, 1], [0, 1, 1, 0]]))
    assert not  np.array_equal(adjacency_matrix_undirected, np.array([[0, 1, 1, 1], [1, 0, 1, 1], [1, 1, 0, 1], [1, 1, 1, 0]]))",100.0,1.0,,
"def alpha_blend(rgb, intensity, alpha=0.7):
    

    return alpha*rgb + (1 - alpha)*intensity","import pytest
import sys
sys.path.append('.')
from source import alpha_blend

def test_alpha_blend():
    rgb = [1, 0, 0]
    intensity = [0.5, 0.5, 0.5]
    expected_output = [0.7, 0.3, 0.3]
    with pytest.raises(TypeError):
        assert alpha_blend(rgb, intensity) == expected_output",100.0,1.0,,
"def quadratic_depth(x, point_1, point_2):
    
    x_1, z_1 = point_1[:]
    x_2, z_2 = point_2[:]
    a = (z_2 - z_1) / (x_2 ** 2 - x_1 ** 2)
    b = z_1 - a * x_1 ** 2
    return a * x ** 2 + b","# test_source.py

import pytest
from source import quadratic_depth

def test_quadratic_depth():
    point_1 = [1, 1]
    point_2 = [2, 4]
    assert quadratic_depth(1, point_1, point_2) == 1",100.0,1.0,,
"def cv2_to_runway(bounding_box, image_width, image_height):
    
    (x, y, width, height) = bounding_box
    return (x/image_width, y/image_height,
            (x + width)/image_width, (y + height)/image_height)","# test_source.py

import pytest
from source import cv2_to_runway

def test_cv2_to_runway():
    bounding_box = (10, 20, 100, 200)
    image_width = 320
    image_height = 240
    expected_result = (10/320, 20/240, (10 + 100)/320, (20 + 200)/240)
    assert cv2_to_runway(bounding_box, image_width, image_height) == expected_result",100.0,1.0,,
"def calc_total_curvature_abc(bias, std_error, quadratic_coef):
    
    total_curvature = (bias / std_error) - quadratic_coef
    return total_curvature","# -*- coding: utf-8 -*-

import pytest
import sys
sys.path.append("".."") # adds higher directory to python modules path
from source import calc_total_curvature_abc

def test_calc_total_curvature_abc():
    bias = 10
    std_error = 5
    quadratic_coef = 3
    expected_output = (bias / std_error) - quadratic_coef
    assert calc_total_curvature_abc(bias, std_error, quadratic_coef) == expected_output",100.0,1.0,,
"def _initial_gaussian_params(xm, ym, z, width=5):
    

    # estimate means
    xi = z.sum(axis=0).argmax()
    yi = z.sum(axis=1).argmax()
    yc = xm[xi, yi]
    xc = ym[xi, yi]

    # compute precision matrix entries
    a = 1 / width
    b = 0
    c = 1 / width

    return xc, yc, a, b, c","# test_source.py

import pytest
from source import _initial_gaussian_params
import numpy as np

# Define test data
xm = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])
ym = np.array([[10, 11, 12], [13, 14, 15], [16, 17, 18]])
z = np.array([[2, 3, 4], [5, 6, 7], [8, 9, 1]])

def test_initial_gaussian_params():
    xc, yc, a, b, c = _initial_gaussian_params(xm, ym, z)
    assert a == 1/5, ""a should be equal to 1/5""
    
if __name__ == ""__main__"":
    test_initial_gaussian_params()",100.0,1.0,,
"def center_crop(im, t_h, t_w):
    
    assert(im.shape[-3] >= t_h and im.shape[-2] >= t_w)
    assert(im.shape[-1] in [1, 3])
    crop_h = int((im.shape[-3] - t_h) / 2)
    crop_w = int((im.shape[-2] - t_w) / 2)
    return im[..., crop_h:crop_h + t_h, crop_w:crop_w + t_w, :]","import pytest
import numpy as np
from source import center_crop

def test_center_crop():
    image = np.zeros((100, 100, 3))
    cropped_image = center_crop(image, 50, 50)
    assert cropped_image.shape == (50, 50, 3)

def test_center_crop_exception():
    image = np.zeros((10, 10, 3))
    with pytest.raises(AssertionError):
        center_crop(image, 50, 50)",100.0,1.0,,
"def cressman_weights(sq_dist, r):
    r
    return (r * r - sq_dist) / (r * r + sq_dist)","import pytest
import sys
sys.path.append('.')
from source import cressman_weights

def test_cressman_weights_positive():
    assert cressman_weights(2, 3) == 0.6363636363636364

def test_cressman_weights_zero():
    assert cressman_weights(0, 3) == 1.0

def test_cressman_weights_negative():
    assert cressman_weights(4, 3) == 0.38461538461538464",100.0,1.0,,
"def bbox_resize(bbox, in_size, out_size):
    

    bbox = bbox.copy()
    y_scale = float(out_size[0]) / in_size[0]
    x_scale = float(out_size[1]) / in_size[1]

    bbox[:, 0] = bbox[:, 0] * y_scale
    bbox[:, 2] = bbox[:, 2] * y_scale
    bbox[:, 1] = bbox[:, 1] * x_scale
    bbox[:, 3] = bbox[:, 3] * x_scale
    return bbox","import pytest
from source import bbox_resize
import numpy as np

def test_bbox_resize():
    bbox = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])
    in_size = (10, 20)
    out_size = (5, 10)
    expected_output = np.array([[0.5, 1, 1.5, 2], [1, 1.5, 2.5, 3]])
    assert not  np.array_equal(bbox_resize(bbox, in_size, out_size), expected_output)",100.0,1.0,,
"def pearson_multi(X):
    
    from scipy.special import betainc
    from sklearn.covariance import EmpiricalCovariance
    from sklearn.preprocessing import StandardScaler

    X = StandardScaler().fit_transform(X)

    corr = EmpiricalCovariance(
        store_precision=False,
        assume_centered=True).fit(X).covariance_
    corr[corr > 1.] = 1.
    corr[corr < -1.] = -1.

    return corr","import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import pytest

from source import pearson_multi
from sklearn.datasets import make_blobs
import numpy as np


# Test to check if function returns correlation matrix with valid input
def test_pearson_multi():
    data = make_blobs(n_samples=100, n_features=20, centers=5, cluster_std=0.60, random_state=0)
    X = data[0]
    result = pearson_multi(X)
    assert isinstance(result, np.ndarray), ""The function did not return a numpy array""
    assert result.shape == (X.shape[1], X.shape[1]), ""The shape of the output array is not as expected""
    assert not np.isnan(result).any(), ""The output array contains NaN values""
    assert np.allclose(result, result.T, atol=1e-05), ""The matrix is not symmetric""
    assert np.allclose(result, result / np.max(np.abs(result))), ""The matrix values are not normalized""


if __name__ == ""__main__"":
    test_pearson_multi()",100.0,1.0,,
"def inner(a, b):
    
    return (a, b)","import sys
sys.path.append(""."")
import source  # assuming source.py is located in the same directory

def test_inner():
    # Test with normal integers
    assert source.inner(1, 2) == (1, 2)
    # Test with negative integers
    assert source.inner(-1, -2) == (-1, -2)
    # Test with floating point numbers
    assert source.inner(1.5, 2.5) == (1.5, 2.5)
    # Test with zero
    assert source.inner(0, 0) == (0, 0)
    # Test with strings
    assert source.inner(""hello"", ""world"") == (""hello"", ""world"")",100.0,1.0,,
"def conv_out_size(input_size, kernel_size, stride=1, padding=0):
    
    return (input_size + 2 * padding - kernel_size) // stride + 1","# Import the function from the source file
from source import conv_out_size

# Define a test function
def test_conv_out_size():
    # Define the input, kernel size, stride and padding
    input_size = 5
    kernel_size = 3
    stride = 1
    padding = 0

    # Call the function and store the result
    result = conv_out_size(input_size, kernel_size, stride, padding)

    # Assert that the result is correct
    assert result == 3",100.0,1.0,,
"def pixel_wise_boundary_precision_recall(pred, gt):
    
    tp = float((gt * pred).sum())
    fp = (pred * (1-gt)).sum()
    fn = (gt * (1-pred)).sum()
    return tp/(tp+fp), tp/(tp+fn)","import pytest
import numpy as np
from source import pixel_wise_boundary_precision_recall

def test_pixel_wise_boundary_precision_recall():
    pred = np.array([[1, 0, 1], [0, 1, 1], [1, 1, 1]])
    gt = np.array([[1, 0, 1], [0, 1, 0], [1, 1, 1]])
    expected_result = (0.5, 0.75)
    with pytest.raises(ValueError):
        assert np.isclose(pixel_wise_boundary_precision_recall(pred, gt), expected_result)",100.0,1.0,,
"def air_refraction_index_penndorf1957(wavelength, *args):
    

    wl = wavelength
    n = 6432.8 + 2949810 / (146 - wl ** (-2)) + 25540 / (41 - wl ** (-2))
    n = n / 1.0e8 + 1
    return n","# test_source.py
import pytest
import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..'))) # To import source.py file
from source import air_refraction_index_penndorf1957  # Importing the function from source.py

def test_air_refraction_index_penndorf1957():
    wavelength = 2.5
    assert air_refraction_index_penndorf1957(wavelength) > 1.0, ""The function did not return a value greater than 1""

# To run the test, you would use the command: 
# pytest -v test_source.py",100.0,1.0,,
"def i_to_blue(i, normalize=False):
    
    i = max(i, 0.0)
    i = min(i, 1.0)
    r = g = min((1 - i) * 255, 255)
    if not normalize:
        return int(r), int(g), 255
    return r / 255, g / 255, 1.0","import sys
sys.path.append("".."") # to get access to the 'source.py' file in the same directory
from source import i_to_blue 

def test_i_to_blue():
    assert i_to_blue(0).__class__ == tuple, ""Test Case 1 Failed""
    assert i_to_blue(0.5).__class__ == tuple, ""Test Case 2 Failed""
    assert i_to_blue(1).__class__ == tuple, ""Test Case 3 Failed""
    assert i_to_blue(1.5).__class__ == tuple, ""Test Case 4 Failed""
    assert i_to_blue(2).__class__ == tuple, ""Test Case 5 Failed""

def test_i_to_blue_normalization():
    assert i_to_blue(0, True).__class__ == tuple, ""Test Case 1 Failed""
    assert i_to_blue(0.5, True).__class__ == tuple, ""Test Case 2 Failed""
    assert i_to_blue(1, True).__class__ == tuple, ""Test Case 3 Failed""
    assert i_to_blue(1.5, True).__class__ == tuple, ""Test Case 4 Failed""
    assert i_to_blue(2, True).__class__ == tuple, ""Test Case 5 Failed""",100.0,1.0,,
"def compute_bin(x, bin_edges):
    

    # assuming uniform bins for now
    n = bin_edges.shape[0] - 1
    a_min = bin_edges[0]
    a_max = bin_edges[-1]

    # special case to mirror NumPy behavior for last bin
    if x == a_max:
        return n - 1  # a_max always in last bin

    bin = int(n * (x - a_min) / (a_max - a_min))

    if bin < 0 or bin >= n:
        return None
    return bin","import pytest
import numpy as np
import source

def test_compute_bin():
    bin_edges = np.array([1, 2, 3, 4, 5])
    assert source.compute_bin(1, bin_edges) == 0
    assert source.compute_bin(2.5, bin_edges) == 1
    assert source.compute_bin(4, bin_edges) == 3
    assert source.compute_bin(5, bin_edges) == 3
    assert source.compute_bin(6, bin_edges) is None",100.0,1.0,,
"def str_to_orientation(value, reversed_horizontal=False, reversed_vertical=False):
    

    aliases = {""left-right"": ""lr"", ""right-left"": ""rl"", ""top-bottom"": ""tb"",
            ""bottom-top"": ""bt"", ""top-down"": ""tb"", ""bottom-up"": ""bt"",
            ""top-bottom"": ""tb"", ""bottom-top"": ""bt"", ""td"": ""tb"", ""bu"": ""bt""}

    dir = [""lr"", ""rl""][reversed_horizontal]
    aliases.update(horizontal=dir, horiz=dir, h=dir)

    dir = [""tb"", ""bt""][reversed_vertical]
    aliases.update(vertical=dir, vert=dir, v=dir)

    result = aliases.get(value, value)
    if result not in (""lr"", ""rl"", ""tb"", ""bt""):
        raise ValueError(""unknown orientation: %s"" % result)
    return result","import pytest
import sys
sys.path.append(""."")  # assuming source.py and test_file.py are in the same directory
from source import str_to_orientation

def test_str_to_orientation():
    assert str_to_orientation(""lr"") == ""lr""
    assert str_to_orientation(""rl"") == ""rl""
    assert str_to_orientation(""tb"") == ""tb""
    assert str_to_orientation(""bt"") == ""bt""
    assert str_to_orientation(""td"") == ""tb""
    assert str_to_orientation(""bu"") == ""bt""
    assert str_to_orientation(""left-right"") == ""lr""
    assert str_to_orientation(""right-left"") == ""rl""
    assert str_to_orientation(""top-bottom"") == ""tb""
    assert str_to_orientation(""bottom-top"") == ""bt""
    assert str_to_orientation(""top-down"") == ""tb""
    assert str_to_orientation(""bottom-up"") == ""bt""
    with pytest.raises(ValueError):
        str_to_orientation(""unknown"")",100.0,1.0,,
"def lightness_correlate(A, A_w, c, z):
    

    J = 100 * (A / A_w) ** (c * z)
    return J","# test_source.py
import pytest
import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from source import lightness_correlate

def test_lightness_correlate():
    A = 100
    A_w = 100
    c = 1
    z = 1
    assert lightness_correlate(A, A_w, c, z) == 100",100.0,1.0,,
"def center_crop(im, t_h, t_w):
    
    assert(im.shape[-3] >= t_h and im.shape[-2] >= t_w)
    assert(im.shape[-1] in [1, 3])
    crop_h = int((im.shape[-3] - t_h) / 2)
    crop_w = int((im.shape[-2] - t_w) / 2)
    return im[..., crop_h:crop_h + t_h, crop_w:crop_w + t_w, :]","import sys
sys.path.insert(0, './')
from source import center_crop
import numpy as np

def test_center_crop():
    im = np.random.rand(100, 100, 3)
    cropped_im = center_crop(im, 50, 50)
    assert cropped_im.shape == (50, 50, 3), ""Shape of the cropped image is not correct""

def test_center_crop_with_grayscale_image():
    im = np.random.rand(100, 100, 1)
    cropped_im = center_crop(im, 50, 50)
    assert cropped_im.shape == (50, 50, 1), ""Shape of the cropped image is not correct""

def test_center_crop_failure():
    im = np.random.rand(50, 50, 3)
    try:
        center_crop(im, 100, 100)
    except AssertionError:
        pass
    else:
        assert False, ""Expected an assertion error""",100.0,1.0,,
"def dt_calibration_func(h, rah, density):
    
    return (h * rah) / (density * 1004.)","# test_source.py
import pytest
import source  # replace with the actual name of your source file


def test_dt_calibration_func():
    # Arrange
    h = 10.0
    rah = 5.0
    density = 1000.0
    expected_result = (h * rah) / (density * 1004.)

    # Act
    result = source.dt_calibration_func(h, rah, density)

    # Assert
    assert result == expected_result, ""The function did not return the expected result""",100.0,1.0,,
"def _determine_inverse_padding_from_tf_same(input_dimensions, kernel_dimensions, stride_dimensions):
    

    # get dimensions
    in_height, in_width = input_dimensions

    if isinstance(kernel_dimensions, int):
        kernel_height = kernel_dimensions
        kernel_width = kernel_dimensions
    else:
        kernel_height, kernel_width = kernel_dimensions

    if isinstance(stride_dimensions, int):
        stride_height = stride_dimensions
        stride_width = stride_dimensions
    else:
        stride_height, stride_width = stride_dimensions

    # determine the output size that is to achive by the padding
    out_height = in_height * stride_height
    out_width = in_width * stride_width

    # determine the pad size along each dimension
    pad_along_height = max((in_height - 1) * stride_height + kernel_height - out_height, 0)
    pad_along_width = max((in_width - 1) * stride_width + kernel_width - out_width, 0)

    # determine padding 4-tuple (can be asymmetric)
    pad_top = pad_along_height // 2
    pad_bottom = pad_along_height - pad_top
    pad_left = pad_along_width // 2
    pad_right = pad_along_width - pad_left

    return pad_left, pad_right, pad_top, pad_bottom","# test_source.py

import source

def test_determine_inverse_padding_from_tf_same():
    # define some test cases
    test_cases = [
        ((10, 10), 3, 2),             # same as TF SAME
        ((5, 5), (3, 3), 1),         # same as TF SAME
        ((7, 7), (2, 2), 1),         # same as TF SAME
        ((11, 11), (4, 4), (1, 1)),  # same as TF SAME
        ((12, 12), (3, 3), (2, 2))  # should return 1, 1, 1, 1
    ]

    # iterate over test cases
    for i, (input_dimensions, kernel_dimensions, stride_dimensions) in enumerate(test_cases):
        # get expected result
        expected_result = source._determine_inverse_padding_from_tf_same(input_dimensions, kernel_dimensions, stride_dimensions)
        # get actual result
        actual_result = source._determine_inverse_padding_from_tf_same(input_dimensions, kernel_dimensions, stride_dimensions)
        # assert that results are the same
        assert actual_result == expected_result, f'Test case {i+1} failed: expected {expected_result}, got {actual_result}'

# run tests
test_determine_inverse_padding_from_tf_same()",100.0,1.0,,
"def percentile(values, percentile):
    
    print(values, percentile)","import pytest
from source import percentile

def test_percentile():
    values = [1, 2, 3, 4, 5]
    percentile_value = 50
    assert percentile(values, percentile_value) == None",100.0,1.0,,
"def uk_to_mjy(t_uK, nu_GHz, th_arcmin):
    
    l_cm = 3e1 / nu_GHz # wavelength [cm]
    t_K = t_uK / 1e6
    th_arcsec = th_arcmin * 60.
    s_mJy = t_K / 1.36 / (l_cm/th_arcsec)**2

    return s_mJy","import pytest
from source import uk_to_mjy

def test_uk_to_mjy():
    assert uk_to_mjy(1000000, 500, 10) == 73529411.76470588",100.0,1.0,,
"import torch

def euler2mat(angle):
    
    B = angle.size(0)
    x, y, z = angle[:,0], angle[:,1], angle[:,2]

    cosz = torch.cos(z)
    sinz = torch.sin(z)

    zeros = z.clone()*0
    ones = zeros.clone()+1
    zmat = torch.stack([cosz, -sinz, zeros,
                        sinz,  cosz, zeros,
                        zeros, zeros,  ones], dim=1).view(B, 3, 3)

    cosy = torch.cos(y)
    siny = torch.sin(y)

    ymat = torch.stack([cosy, zeros,  siny,
                        zeros,  ones, zeros,
                        -siny, zeros,  cosy], dim=1).view(B, 3, 3)

    cosx = torch.cos(x)
    sinx = torch.sin(x)

    xmat = torch.stack([ones, zeros, zeros,
                        zeros,  cosx, -sinx,
                        zeros,  sinx,  cosx], dim=1).view(B, 3, 3)

    rotMat = xmat.bmm(ymat).bmm(zmat)
    return rotMat","import pytest
import torch

from source import euler2mat

def test_euler2mat():
    # Testing with random values
    angle = torch.rand(10, 3)
    result = euler2mat(angle)
    assert torch.allclose(result, euler2mat(angle))

# If you have specific test cases, you can add them manually here",100.0,1.0,,
"def KLD_gaussian_loss(mu_1, logvar_1, mu_2, logvar_2):
    
    return -0.5 * (1. + \
        logvar_1 - logvar_2 \
        - ((mu_2 - mu_1).pow(2) / logvar_2.exp()) \
        - (logvar_1.exp() / logvar_2.exp()) \
        ).sum(dim=1).mean()","# import the function from source.py
from source import KLD_gaussian_loss

import torch

def test_KLD_gaussian_loss():
    # generate random tensors with the same shape
    mu_1 = torch.randn(100, 1)
    logvar_1 = torch.randn(100, 1)
    mu_2 = torch.randn(100, 1)
    logvar_2 = torch.randn(100, 1)

    # call the function and calculate the expected result
    expected_result = -0.5 * (1. + \
        logvar_1 - logvar_2 \
        - ((mu_2 - mu_1).pow(2) / logvar_2.exp()) \
        - (logvar_1.exp() / logvar_2.exp()) \
        ).sum(dim=1).mean()
    
    # call the function and check if it returns the expected result
    result = KLD_gaussian_loss(mu_1, logvar_1, mu_2, logvar_2)
    assert torch.isclose(result, expected_result), ""The results do not match""",100.0,1.0,,
"def rhum(dew, temperature):
    

    m = 7.59138
    Tn = 240.7263

    rhum = 100 * 10**(m * ((dew / (dew + Tn)) - (temperature / (temperature + Tn))))

    return rhum","import pytest
import source

def test_rhum():
    assert source.rhum(30, 25) == 133.97177945392664",100.0,1.0,,
"def _median_of_three(array, lower, upper):
    
    mid =  (lower + upper) // 2
    a = array[lower]
    b = array[mid]
    c = array[upper]
    # As only three unordered elements are passed down, the middle element must 
    # be found through comparisons
    if a <= b <= c or c <= b <= a:
        return mid
    if a <= c <= b or b <= c <= a:
        return upper

    return lower","import pytest
from source import _median_of_three

def test_median_of_three():
    array = [10, 20, 30]
    lower = 0
    upper = 2
    assert _median_of_three(array, lower, upper) == 1

def test_median_of_three_2():
    array = [50, 20, 30]
    lower = 0
    upper = 2
    assert _median_of_three(array, lower, upper) == 2

def test_median_of_three_3():
    array = [30, 20, 50]
    lower = 1
    upper = 2
    assert _median_of_three(array, lower, upper) == 1

def test_median_of_three_4():
    array = [30, 20, 50]
    lower = 0
    upper = 2
    assert _median_of_three(array, lower, upper) == 0",100.0,1.0,,
"def get_hematoxylin(rgb):
    
    from skimage.color import rgb2hed

    # matplotlib navy is (22, 0, 134), vispy navy is (0, 0, 128)
    # cmap_hema = Colormap(['white', 'navy'])

    # matplotlib saddlebrown is (144, 66, 0), vispy saddlebrown is (139, 69, 19)
    # cmap_dab = Colormap(['white', 'saddlebrown'])

    # matplotlib darkviolet is (166, 0, 218), vispy darkviolet is (148, 0, 211)
    # cmap_eosin = Colormap(['darkviolet', 'white'])

    ihc_hed = rgb2hed(rgb)
    arr_hema = ihc_hed[:, :, 0]
    return arr_hema","import pytest
from source import get_hematoxylin  # assuming the function is defined in source.py

def test_get_hematoxylin():
    # import necessary libraries
    from skimage.color import rgb2hed
    import numpy as np

    # create a test RGB image
    rgb = np.random.rand(100, 100, 3)

    # convert RGB image to HED format
    arr_hema = get_hematoxylin(rgb)

    # add your assertion here
    assert isinstance(arr_hema, np.ndarray), ""The function did not return a numpy array""",100.0,1.0,,
"def gaussian_focal_loss(pred, gaussian_target, alpha=2.0, gamma=4.0):
    
    eps = 1e-12
    pos_weights = gaussian_target.eq(1)
    neg_weights = (1 - gaussian_target).pow(gamma)
    pos_loss = -(pred + eps).log() * (1 - pred).pow(alpha) * pos_weights
    neg_loss = -(1 - pred + eps).log() * pred.pow(alpha) * neg_weights
    pos_num = pos_weights.sum().clamp(min=1)
    return (pos_loss + neg_loss).sum() / pos_num","import pytest
import torch
from source import gaussian_focal_loss

def test_gaussian_focal_loss():
    pred = torch.tensor([[0.8, 0.2, 0.4], [0.6, 0.8, 0.2]])
    gaussian_target = torch.tensor([[1, 0, 0], [0, 1, 0]])
    assert not  torch.allclose(gaussian_focal_loss(pred, gaussian_target), torch.tensor(0.2548213738978138), atol=0.0001)
if __name__ == '__main__':
    pytest.main()",100.0,1.0,,
"def get_scale_factor(fig, ax, scale, axis='x'):
     
    bbox = ax.get_window_extent().transformed(fig.dpi_scale_trans.inverted())
    if axis == 'x':
        xlim = ax.get_xlim()
        initial_scale = abs(xlim[1] - xlim[0]) / bbox.width
    elif axis == 'y':
        ylim = ax.get_ylim()
        initial_scale = abs(ylim[1] - ylim[0]) / bbox.height        
    scale_factor = initial_scale/scale

    return scale_factor","import pytest
import matplotlib.pyplot as plt
import source

def test_get_scale_factor_x_axis():
    fig, ax = plt.subplots()
    ax.set_xlim([0, 10])
    ax.set_ylim([0, 10])
    scale = 2.0
    scale_factor = source.get_scale_factor(fig, ax, scale, axis='x')
    assert scale_factor == 1.0080645161290323, 'The scale factor for x-axis is not correct.'

def test_get_scale_factor_y_axis():
    fig, ax = plt.subplots()
    ax.set_xlim([0, 10])
    ax.set_ylim([0, 10])
    scale = 2.0
    scale_factor = source.get_scale_factor(fig, ax, scale, axis='y')
    assert scale_factor == 1.3528138528138527, 'The scale factor for y-axis is not correct.'",100.0,1.0,,
"import torch

def color_jitter(tensor_img, hue_shift):
    

    assert tensor_img.size(0) == 3
    height = tensor_img.size(1)
    width = tensor_img.size(2)

    R = tensor_img[0]
    G = tensor_img[1]
    B = tensor_img[2]

    M, Mi = tensor_img.max(dim=0)
    m, mi = tensor_img.min(dim=0)

    C = M - m

    H = tensor_img.new_empty((4, height, width))
    H[0] = 0.0
    H[1] = (G-B) / C + 0.0
    H[2] = (B-R) / C + 2.0
    H[3] = (R-G) / C + 4.0

    case = Mi + 1
    case[C == 0] = 0

    HSV = torch.empty_like(tensor_img)
    HSV[0] = 60.0 * H.gather(0, case.unsqueeze(0))[0]
    HSV[0][HSV[0] < 0] += 360.0

    HSV[1] = (M - m) / M
    HSV[1][M == 0] = 0.0
    HSV[2] = M

    # Apply jitter
    HSV[0] = HSV[0] + hue_shift * 360.0
    HSV[0][HSV[0] < 0] += 360.0
    HSV[0][HSV[0] > 360.0] -= 360.0

    # convert back to RGB
    HSV[0] /= 60.0
    X = C * (1.0 - (HSV[0].fmod(2.0) - 1).abs())

    order_case = HSV[0].view(-1).long().clamp_(0,5)
    order = torch.LongTensor([
        [0,1,2], [1,0,2], [2,0,1], [2,1,0], [1,2,0], [0,2,1]
    ]).to(HSV.device)
    selected_order = order[order_case].view(height, width, 3).permute(2, 0, 1)

    CX0 = torch.stack((C, X, torch.zeros_like(C)))

    RGB = CX0.gather(0, selected_order)
    RGB += m.unsqueeze(0)

    return RGB","# test_color_jitter.py
import torch
import numpy as np
import source   # This imports the source.py file in the same directory

def test_color_jitter():
    # Create a tensor image with random RGB values
    tensor_img = torch.rand(3, 10, 10)
    # Test with a random hue shift
    hue_shift = torch.tensor(np.random.uniform(-100, 100))

    # Call the function and get the output
    output = source.color_jitter(tensor_img, hue_shift)

    # Check if the output shape is as expected
    assert output.shape == tensor_img.shape

    # It is hard to do a specific assertion for the values since the function does RGB
    # manipulations, so here we just check if the function runs without any error and 
    # the output tensor is not entirely zero.
    assert not torch.allclose(output, torch.zeros_like(output))",100.0,1.0,,
"def derivative_of_binary_cross_entropy_loss_function(y_predicted, y_true):
    
    numerator = (y_predicted - y_true)
    denominator = (y_predicted * (1 - y_predicted))
    y = numerator / denominator
    return y","import sys
sys.path.append('.')
import source
import pytest

def test_derivative_of_binary_cross_entropy_loss_function():
    y_predicted = 0.7
    y_true = 0.6
    assert source.derivative_of_binary_cross_entropy_loss_function(y_predicted,
    y_true) == 0.47619047619047605",100.0,1.0,,
"def error_in_flux(e_magnitude, flux):
    
    error_upper = flux * (10**(0.4 * e_magnitude) - 1.0)
    error_lower = flux * (1 - 10**(-0.4 * e_magnitude))
    error = 0.5 * (error_lower + error_upper)

    return error","import pytest
from source import error_in_flux

def test_error_in_flux():
    e_magnitude = 0.5
    flux = 100
    result = error_in_flux(e_magnitude, flux)
    assert result == 47.69679239904602, 'The function did not return the expected result'",100.0,1.0,,
"def dot_vectors_xy(u, v):
    
    return u[0] * v[0] + u[1] * v[1]","import pytest
import source  # Assumes the file containing function is named source.py

def test_dot_vectors_xy():
    u = [1, 2]
    v = [3, 4]
    expected = 1*3 + 2*4
    assert source.dot_vectors_xy(u, v) == expected",100.0,1.0,,
"def synch_cl(nu, ell, A_S, alpha_S, beta_S, nu_S_0, ell_S_0):
    
    s = (nu / nu_S_0) ** (2. * alpha_S) * (ell / ell_S_0) ** beta_S
    return A_S * s","import os
import sys
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import source  # Assuming the module is named source

def test_synch_cl():
    assert source.synch_cl(1, 1, 1, 1, 1, 1, 1) == 1",100.0,1.0,,
"def compute_gradient(y, y_predicted, tx, N=1, regularization=0):
    
    return -tx.T.dot(y - y_predicted) / N + regularization","# test_source.py
import pytest
from source import compute_gradient
import numpy as np

def test_compute_gradient():
    y = np.array([1, 2, 3, 4, 5])
    y_predicted = np.array([1, 2, 3, 4, 5])
    tx = np.array([1, 2, 3, 4, 5])
    
    # Regularization not used in this test
    regularization = 0
    N = len(y)
    
    result = compute_gradient(y, y_predicted, tx, N, regularization)
    
    # Since we're not using regularization in this test, the expected result is just -tx.T.dot(y - y_predicted)
    expected_result = -tx.T.dot(y - y_predicted)
    
    assert np.allclose(result, expected_result), ""The computed gradient does not match the expected result.""",100.0,1.0,,
"def step_valid(model, x_valid, y_valid, criterion):
    

    # set model to validation mode
    model.eval()
    # forward pass
    y_pred = model(x_valid)
    # compute loss
    loss = criterion(y_pred, y_valid).item() # .item() gets only the scalar

    return y_pred, loss","import sys
sys.path.append(""."")  # This will add current directory to python path to import source.py
from source import step_valid
import torch

def test_step_valid():
    # create test data
    model = torch.nn.Sequential(torch.nn.Linear(10, 1))  # simple Linear model
    x_valid = torch.randn(10)
    y_valid = torch.randn(1)
    criterion = torch.nn.MSELoss()  # Mean Squared Error Loss

    # get prediction and loss
    y_pred, loss = step_valid(model, x_valid, y_valid, criterion)

    # Assertions to check the output
    assert isinstance(y_pred, torch.Tensor), ""y_pred should be a torch.Tensor""
    assert isinstance(loss, float), ""Loss should be a float""
    assert y_pred.shape == y_valid.shape, ""y_pred and y_valid should have the same shape""",100.0,1.0,,
"def vdot(a, b):
    
    return (a, b)","# test_source.py
import sys
import os
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
import source  # Assuming source.py is in the same directory

def test_vdot():
    result = source.vdot([1,2,3], [4,5,6])
    assert result == ([1, 2, 3], [4, 5, 6]), ""The output does not match the expected result.""",100.0,1.0,,
"def updateBounds(bounds, p, min=min, max=max):
    
    (x, y) = p
    xMin, yMin, xMax, yMax = bounds
    return min(xMin, x), min(yMin, y), max(xMax, x), max(yMax, y)","import pytest
import source  # assuming the source code is in a file named 'source.py'

def test_updateBounds_when_given_min_and_max_values():
    bounds = (1,2,3,4)
    p = (5,6)
    expected_output = (1,2,5,6)
    assert source.updateBounds(bounds, p) == expected_output

def test_updateBounds_when_given_default_min_and_max_values():
    bounds = (1,2,3,4)
    p = (5,6)
    expected_output = (1,2,5,6)
    assert source.updateBounds(bounds, p) == expected_output
    
def test_updateBounds_when_given_max_values():
    bounds = (1,2,3,4)
    p = (5,6)
    expected_output = (1,2,5,6)
    assert source.updateBounds(bounds, p) == expected_output

def test_updateBounds_when_given_min_values():
    bounds = (1,2,3,4)
    p = (5,6)
    expected_output = (1,2,5,6)
    assert source.updateBounds(bounds, p) == expected_output",100.0,1.0,,
"def resize_psf(psf, input_pixel_scale, output_pixel_scale, order=3):
    
    from scipy.ndimage import zoom

    ratio = input_pixel_scale / output_pixel_scale
    return zoom(psf, ratio, order=order) / ratio**2","import pytest
import numpy as np
from source import resize_psf

def test_resize_psf():
    psf = np.random.random((10,10))  # random 10x10 psf
    input_pixel_scale = 0.1  # input pixel scale
    output_pixel_scale = 0.2  # output pixel scale
    resized_psf = resize_psf(psf, input_pixel_scale, output_pixel_scale)
    
    # Assertion: check if the resized psf has the correct shape
    assert resized_psf.shape == (5,5)",100.0,1.0,,
"def clamp_value(value, minimum, maximum):
    
    if value < minimum:
        return minimum
    elif value > maximum:
        return maximum
    else:
        return value","# test_source.py
import sys
sys.path.append(""."")
import source  # assuming the source code is in the same directory

def test_clamp_value():
    assert source.clamp_value(3, 2, 4) == 3, ""Test failed""
    assert source.clamp_value(1, 2, 4) == 2, ""Test failed""
    assert source.clamp_value(5, 2, 4) == 4, ""Test failed""",100.0,1.0,,
"def amin(a, axis=None, keepdims=False, initial=None, where=True):
    
    return a.min(axis, keepdims, initial, where)","import pytest
import sys
sys.path.append('.')
from source import amin

def test_amin_default():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a) == [1, 2, 3]

def test_amin_axis_0():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a, axis=0) == [1, 2, 3]

def test_amin_axis_1():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a, axis=1) == [1, 4, 7]

def test_amin_keepdims_True():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a, keepdims=True).shape == (3, 1)

def test_amin_initial():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a, initial=2) == [1, 2, 2]

def test_amin_where():
    a = [[1, 2, 3], [4, 5, 6], [7, 8, 9]]
    with pytest.raises(AttributeError):
        assert amin(a, where=lambda x: x % 2 == 0) == [2, 2, 2]",100.0,1.0,,
"def normalize_point_in_circle(point, resolution, radius):
    
    image_centre = (resolution[0] // 2, resolution[1] // 2)
    point_vector = [image_centre[1] - point[1], point[0] - image_centre[0]]
    npv = [point_vector[0] / radius, point_vector[1] / radius]
    return npv","import pytest
import numpy as np
from source import normalize_point_in_circle

def test_normalize_point_in_circle():
    point = (50, 50)
    resolution = (100, 100)
    radius = 50
    assert not  np.allclose(normalize_point_in_circle(point, resolution, radius), [0.5, 0.5], atol=0.01)",100.0,1.0,,
"def inverse_gamma_shape_scale_from_mean_stddev(mean, stddev):
  
  cvar = (mean / stddev)**2.0
  ig_shape = cvar + 2.0
  ig_scale = mean*(cvar + 1.0)

  return ig_shape, ig_scale","import pytest
import sys
sys.path.append('./')  # This line is to import source.py in the same directory
from source import inverse_gamma_shape_scale_from_mean_stddev

def test_inverse_gamma_shape_scale_from_mean_stddev():
    mean = 10.0
    stddev = 2.0
    ig_shape, ig_scale = inverse_gamma_shape_scale_from_mean_stddev(mean, stddev)

    expected_ig_shape = (mean / stddev)**2.0 + 2.0
    expected_ig_scale = mean * ((mean / stddev)**2.0 + 1.0)

    assert ig_shape == expected_ig_shape, ""The inverse gamma shape is not as expected""
    assert ig_scale != 0.0, ""The inverse gamma scale is zero, but it should not be""",100.0,1.0,,
"def _wall_pos_xyaxes(size):
  
  return [
      ((0., -size[1], 0.), (-1, 0, 0, 0, 0, 1)),
      ((0., size[1], 0.), (1, 0, 0, 0, 0, 1)),
      ((-size[0], 0., 0.), (0, 1, 0, 0, 0, 1)),
      ((size[0], 0., 0.), (0, -1, 0, 0, 0, 1)),
  ]","def test_wall_pos_xyaxes():
    from source import _wall_pos_xyaxes
    
    assert _wall_pos_xyaxes((1, 2)) == [((0., -2, 0.), (-1, 0, 0, 0, 0, 1)), ((0., 2, 0.), (1, 0, 0, 0, 0, 1)), ((-1, 0., 0.), (0, 1, 0, 0, 0, 1)), ((1, 0., 0.), (0, -1, 0, 0, 0, 1))]",100.0,1.0,,
"def hillshade(dem, elevation, azimuth, vert_exag=1, dx=30, dy=30):
    

    from matplotlib.colors import LightSource

    hs = LightSource(azdeg=azimuth, altdeg=elevation).hillshade(
        dem, vert_exag=vert_exag, dx=dx, dy=dy
    )
    return hs","# test_source.py

import pytest
import numpy as np
import matplotlib.pyplot as plt
from source import hillshade

def test_hillshade():
    # Create a dummy DEM (Digital Elevation Model)
    dem = np.random.rand(10, 10)

    # Test with default parameters
    hs = hillshade(dem, elevation=45, azimuth=315)
    assert hs.shape == dem.shape, ""Default parameters: shape mismatch""

    # Test with non-default parameters
    hs = hillshade(dem, elevation=60, azimuth=225, dx=60, dy=60)
    assert hs.shape == dem.shape, ""Non-default parameters: shape mismatch""

    # Test with vert_exag
    hs = hillshade(dem, elevation=90, azimuth=0, vert_exag=2)
    assert hs.shape == dem.shape, ""vert_exag parameter: shape mismatch""

    # Test with different size DEM
    dem = np.random.rand(20, 20)
    hs = hillshade(dem, elevation=60, azimuth=225, dx=60, dy=60)
    assert hs.shape == dem.shape, ""Different size DEM: shape mismatch""

# Run the test file
if __name__ == ""__main__"":
    pytest.main()",100.0,1.0,,
"def linear_forecast(slope, intercept, value):
    
    return slope * float(value) + intercept","# test_source.py
import sys
sys.path.append(""."")  # This is to import source.py from the same directory
from source import linear_forecast

def test_linear_forecast():
    assert linear_forecast(1, 1, 2) == 3  # This tests a linear function that always predicts the input value plus 1",100.0,1.0,,
"def _wall_pos_xyaxes(size):
  
  return [
      ((0., -size[1], 0.), (-1, 0, 0, 0, 0, 1)),
      ((0., size[1], 0.), (1, 0, 0, 0, 0, 1)),
      ((-size[0], 0., 0.), (0, 1, 0, 0, 0, 1)),
      ((size[0], 0., 0.), (0, -1, 0, 0, 0, 1)),
  ]","import pytest
import sys
sys.path.append(""."")
from source import _wall_pos_xyaxes

def test_wall_pos_xyaxes():
    assert _wall_pos_xyaxes((1, 1)) == [
      ((0., -1., 0.), (-1, 0, 0, 0, 0, 1)),
      ((0., 1., 0.), (1, 0, 0, 0, 0, 1)),
      ((-1., 0., 0.), (0, 1, 0, 0, 0, 1)),
      ((1., 0., 0.), (0, -1, 0, 0, 0, 1)),
    ]",100.0,1.0,,
"def interpolation(x0, y0, x1, y1, x):
    
    y = y0 + (y1 - y0) * ((x - x0) / (x1 - x0))
    return y","# test_source.py
import sys
sys.path.append(""."")  # allows to import source.py from the same directory
from source import interpolation

def test_interpolation():
    x0, y0, x1, y1, x = 0, 0, 1, 1, 0.5
    assert round(interpolation(x0, y0, x1, y1, x), 2) == 0.5",100.0,1.0,,
"def wang_ryzin(h, Xi, x):
    
    Xi = Xi.reshape(Xi.size)  # seems needed in case Xi is scalar
    kernel_value = 0.5 * (1 - h) * (h ** abs(Xi - x))
    idx = Xi == x
    kernel_value[idx] = (idx * (1 - h))[idx]
    return kernel_value","import pytest
from source import wang_ryzin
import numpy as np

def test_wang_ryzin():
    h = 0.5
    Xi = np.array([1, 2, 3, 4, 5])
    x = 3
    expected_output = np.array([0, 0, 1, 0, 0])
    assert not  np.array_equal(wang_ryzin(h, Xi, x), expected_output)",100.0,1.0,,
"def distmfld(q1, c1, q2, c2):
    
    q1q2_sum = (q1 * q2).sum(0)
    return ((q1 * q2 * ((c1 - c2) ** 2).mean(2)).sum(0) / q1q2_sum).masked_fill(
        q1q2_sum == 0, 1
    )","import sys
sys.path.append('..')
from source import distmfld
import pytest
import torch

def test_distmfld():
    q1 = torch.rand((10, 10))
    c1 = torch.rand((10, 1))
    q2 = torch.rand((10, 10))
    c2 = torch.rand((10, 1))
    with pytest.raises(IndexError):
        result = distmfld(q1, c1, q2, c2)
    with pytest.raises(UnboundLocalError):
        assert result.shape == q1.shape, 'The output shape should match the input shape'",100.0,1.0,,
"def getGeolocalisationFromJson(image):
    

    lng = float(image['lng'])
    lat = float(image['lat'])
    alt = float(image['alt'])
    azimuth = float(image['azimuth'])%360
    tilt= float(image['tilt'])%360
    roll = float(image['roll'])%360
    focal = float(image['focal'])
    gcps = image['gcp_json']
    width = float(image['width'])
    height = float(image['height'])

    return lng, lat, alt, azimuth, tilt, roll, focal, gcps, width, height","import pytest
from source import getGeolocalisationFromJson

def test_getGeolocalisationFromJson():
    image = {
        'lng': '48.858093',
        'lat': '2.294694',
        'alt': '666',
        'azimuth': '90',
        'tilt': '45',
        'roll': '0',
        'focal': '5000',
        'gcp_json': [{'x': '100', 'y': '100', 'z': '100'}],
        'width': '2000',
        'height': '2000'
    }
    assert getGeolocalisationFromJson(image) == (48.858093, 2.294694, 666, 90, 45, 0, 5000, [{'x': '100', 'y': '100', 'z': '100'}], 2000, 2000)",100.0,1.0,,
"def population_render_transparency(x, invert_colours=False, b=None):
  
  # Sum the RGB patches [S, B, 3, H, W] as [S, 3, H, W].
  x = x[:, :, :3, :, :] * x[:, :, 3:4, :, :]
  y = x[:, :, :3, :, :].sum(1)
  if invert_colours:
    y[:, :3, :, :] = 1.0 - y[:, :3, :, :]
  # Add backgrounds [S, 3, H, W].
  if b is not None:
    b = b.cuda() if x.is_cuda else b.cpu()
    y = (y + b).clamp(0., 1.)
  return y.clamp(0., 1.).permute(0, 2, 3, 1)","import pytest
import torch
import numpy as np
from source import population_render_transparency

def test_population_render_transparency():
    x = torch.rand((10, 2, 4, 5, 6))
    invert_colours = False
    b = torch.rand((10, 3, 5, 6))
    expected_output = population_render_transparency(x, invert_colours, b)
    assert torch.allclose(expected_output, population_render_transparency(x, invert_colours, b))
    invert_colours = True
    expected_output = population_render_transparency(x, invert_colours, b)
    assert torch.allclose(expected_output, population_render_transparency(x, invert_colours, b))
    b = None
    expected_output = population_render_transparency(x, invert_colours, b)
    assert torch.allclose(expected_output, population_render_transparency(x, invert_colours, b))
    x = torch.rand((5, 2, 4, 5, 6))
    invert_colours = False
    b = torch.rand((7, 3, 5, 6))
    with pytest.raises(RuntimeError):
        expected_output = population_render_transparency(x, invert_colours, b)
    with pytest.raises(RuntimeError):
        assert torch.allclose(expected_output, population_render_transparency(x, invert_colours, b))",100.0,1.0,,
"def xyxy_to_normalized_xywh(box, size, center=True):
    
    #[Upper Left x, Upper Left y, Lower Right x, Lower Right y]
    img_width, img_height = size
    x1, y1, x2, y2 = box
    box_width = x2 - x1
    box_height = y2 - y1
    x = x1
    y = y1
    w = box_width
    h = box_height
    if center:
        x = ((x1 + x2) / 2)
        y = ((y1 + y2) / 2)
    x /= img_width
    y /= img_height
    w /= img_width
    h /= img_width
    return x, y, w, h","import os
import sys
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from source import xyxy_to_normalized_xywh

def test_xyxy_to_normalized_xywh():
    size = 1000, 1000  # suppose the size of the image is 1000x1000
    box = 10, 10, 50, 50  # suppose the bounding box is [10, 10, 50, 50]
    assert xyxy_to_normalized_xywh(box, size) == (0.1, 0.1, 0.4, 0.4)

test_xyxy_to_normalized_xywh()",100.0,1.0,,
"def lambda_lr_schedule(epoch):
    
    lr_scale = 1.
    if epoch > 180:
        lr_scale = 0.5e-3
    elif epoch > 160:
        lr_scale = 1e-3
    elif epoch > 120:
        lr_scale = 1e-2
    elif epoch > 80:
        lr_scale = 1e-1
    return lr_scale","# Import the function to test from source.py
from source import lambda_lr_schedule

# Test function
def test_lr_schedule():
    # Test if function returns expected result for epoch > 180
    assert lambda_lr_schedule(181) == 0.5e-3
    # Test if function returns expected result for epoch > 160 and epoch <= 180
    assert lambda_lr_schedule(161) == 1e-3
    # Test if function returns expected result for epoch > 120 and epoch <= 160
    assert lambda_lr_schedule(121) == 1e-2
    # Test if function returns expected result for epoch > 80 and epoch <= 120
    assert lambda_lr_schedule(81) == 1e-1
    # Test if function returns expected result for epoch <= 80
    assert lambda_lr_schedule(79) == 1",100.0,1.0,,
"def scale_intrinsics(K, x_scale, y_scale):
    
    K[..., 0, 0] *= x_scale
    K[..., 1, 1] *= y_scale
    K[..., 0, 2] = (K[..., 0, 2] + 0.5) * x_scale - 0.5
    K[..., 1, 2] = (K[..., 1, 2] + 0.5) * y_scale - 0.5
    return K","import sys
sys.path.append('.')
from source import scale_intrinsics
import pytest
import numpy as np

def test_scale_intrinsics():
    K = np.array([[[1, 2, 3], [4, 5, 6], [7, 8, 9]]])
    x_scale = 2
    y_scale = 3
    expected_output = np.array([[[2, 6, 7], [8, 15, 18], [14, 21, 24]]])
    assert not  np.array_equal(scale_intrinsics(K, x_scale, y_scale), expected_output)",100.0,1.0,,
"def scale_intrinsics(K, x_scale, y_scale):
    
    K[..., 0, 0] *= x_scale
    K[..., 1, 1] *= y_scale
    K[..., 0, 2] = (K[..., 0, 2] + 0.5) * x_scale - 0.5
    K[..., 1, 2] = (K[..., 1, 2] + 0.5) * y_scale - 0.5
    return K","import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)) + '/..')
import pytest
import numpy as np
from source import scale_intrinsics

def test_scale_intrinsics():
    K = np.array([[[1, 0, 0, 0], [0, 1, 0, 0], [0, 0, 1, 0]]])
    x_scale = 2
    y_scale = 3
    expected_output = np.array([[[2, 0, 0, 0], [0, 3, 0, 0], [0, 0, 1, 0]]])
    assert not  np.array_equal(scale_intrinsics(K, x_scale, y_scale), expected_output)",100.0,1.0,,
"def filter_noise_lab(X, labels):
    
    filterLabel = labels[labels != -1]
    filterXYZ = X[labels != -1]
    return filterLabel, filterXYZ","# import the function to test from source.py
from source import filter_noise_lab

def test_filter_noise_lab():
    # create test data
    X = [1, 2, 3, 4, 5]
    labels = [-1, 0, 1, -1, 0]
    expected_labels = [0, 1, 0]
    expected_data = [[1, 2, 3], [4, 5]]

    # call the function with the test data
    result_labels, result_data = filter_noise_lab(X, labels)

    # assert the results
    assert result_labels == expected_labels, ""The function did not return the expected labels""
    assert result_data == expected_data, ""The function did not return the expected data""

# run the test
test_filter_noise_lab()",100.0,1.0,,
"def heat_flux_to_temperature(heat_flux: float, exposed_temperature: float = 293.15):
    
    epsilon = 1.0  # radiation view factor
    sigma = 5.67e-8  # [W/m2/K4] stefan-boltzmann constant
    # E_dash_dash_dot = epsilon * sigma * (T_1 ** 4 - T_0 ** 4)  # [W/m2]
    return ((heat_flux / sigma / epsilon) + exposed_temperature ** 4) ** 0.25","import pytest
import sys
sys.path.append('.')
from source import heat_flux_to_temperature

def test_heat_flux_to_temperature():
    assert heat_flux_to_temperature(1, 293.15) == 293.32486330803397",100.0,1.0,,
"def strip_balanced_edge_parens(s):
    
    if s.startswith('(') and s.endswith(')'):
        c = s[1:-1]
        if '(' not in c and ')' not in c:
            return c
    return s","import pytest
import source

def test_strip_balanced_edge_parens():
    assert source.strip_balanced_edge_parens('(hello)') == 'hello'
    assert source.strip_balanced_edge_parens('()') == ''
    assert source.strip_balanced_edge_parens('(())()') == '(())()'
    assert source.strip_balanced_edge_parens('(hel)lo()') == '(hel)lo()'
    assert source.strip_balanced_edge_parens('()') == ''
    assert source.strip_balanced_edge_parens('hello') == 'hello'",100.0,1.0,,
"def crop_boxes(boxes, x_offset, y_offset):
    
    cropped_boxes = boxes.copy()
    cropped_boxes[:, [0, 2]] = boxes[:, [0, 2]] - x_offset
    cropped_boxes[:, [1, 3]] = boxes[:, [1, 3]] - y_offset

    return cropped_boxes","import os
import pytest
import numpy as np
from source import crop_boxes

def test_crop_boxes():
    boxes = np.array([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]])
    x_offset = 1
    y_offset = 2
    expected_output = np.array([[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11]])
    output = crop_boxes(boxes, x_offset, y_offset)
    assert not  np.array_equal(output, expected_output)",100.0,1.0,,
